import os
import requests
import datetime
import hashlib
import json
import random
import time
import schedule
import re
from collections import Counter
from dotenv import load_dotenv

load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

HISTORY_FILE = "post_history.json"

class StructuredTelegramPostBot:
    def __init__(self):
        self.history = self.load_history()
        
    def load_history(self):
        try:
            if os.path.exists(HISTORY_FILE):
                with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except:
            pass
        return {
            "post_hashes": [],
            "used_themes": [],
            "used_keywords": [],
            "channel_analysis": {}
        }
    
    def save_history(self):
        try:
            with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
                json.dump(self.history, f, ensure_ascii=False, indent=2)
        except:
            pass

    def get_channel_posts(self, limit=50):
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø–æ—Å—Ç—ã –∏–∑ –∫–∞–Ω–∞–ª–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            url = f"https://api.telegram.org/bot{BOT_TOKEN}/getChatHistory"
            payload = {
                "chat_id": CHANNEL_ID,
                "limit": limit
            }
            
            response = requests.post(url, json=payload, timeout=30)
            if response.status_code == 200:
                data = response.json()
                posts = []
                if data.get("ok") and data.get("result"):
                    for message in data["result"]:
                        content = ""
                        if "text" in message:
                            content = message["text"]
                        elif "caption" in message:
                            content = message["caption"]
                        
                        if content and len(content.strip()) > 30:
                            posts.append(content)
                return posts
        except:
            pass
        return []

    def analyze_channel_content(self, posts):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –∫–∞–Ω–∞–ª–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–º –∏ —Å—Ç–∏–ª—è"""
        if not posts:
            return {"themes": ["HR", "PR", "—Ä–µ–º–æ–Ω—Ç"], "keywords": [], "style": "–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π"}
        
        all_text = " ".join(posts).lower()
        
        theme_keywords = {
            "HR": ["hr", "–ø–µ—Ä—Å–æ–Ω–∞–ª", "—Å–æ—Ç—Ä—É–¥–Ω–∏–∫", "—Ä–µ–∫—Ä—É—Ç–∏–Ω–≥", "–Ω–∞–π–º", "–º–æ—Ç–∏–≤–∞—Ü–∏—è", "–∫–æ–º–∞–Ω–¥–∞", "–∫–∞–¥—Ä"],
            "PR": ["pr", "–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è", "–±—Ä–µ–Ω–¥", "—Ä–µ–ø—É—Ç–∞—Ü", "–º–µ–¥–∏–∞", "–ø—É–±–ª–∏—á–Ω—ã–π", "—Å–º–∏"],
            "—Ä–µ–º–æ–Ω—Ç": ["—Ä–µ–º–æ–Ω—Ç", "—Å—Ç—Ä–æ–∏—Ç–µ–ª—å", "–∫–≤–∞—Ä—Ç–∏—Ä", "–¥–æ–º", "–¥–∏–∑–∞–π–Ω", "–∏–Ω—Ç–µ—Ä—å–µ—Ä", "–æ—Ç–¥–µ–ª–∫", "–º–∞—Ç–µ—Ä–∏–∞–ª"]
        }
        
        detected_themes = []
        for theme, keywords in theme_keywords.items():
            theme_count = sum(1 for keyword in keywords if keyword in all_text)
            if theme_count >= 2:
                detected_themes.append(theme)
        
        words = re.findall(r'\b[–∞-—èa-z]{4,}\b', all_text)
        stop_words = {'—ç—Ç–æ—Ç', '—ç—Ç–æ', '—Ç–∞–∫–∂–µ', '–æ—á–µ–Ω—å', '–º–æ–∂–Ω–æ', '–±—É–¥–µ—Ç', '–µ—Å—Ç—å'}
        word_freq = Counter([word for word in words if word not in stop_words])
        top_keywords = [word for word, count in word_freq.most_common(10)]
        
        return {
            "themes": detected_themes if detected_themes else ["HR", "PR", "—Ä–µ–º–æ–Ω—Ç"],
            "keywords": top_keywords,
            "style": "–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π" if any(word in all_text for word in ["–∫–æ–º–ø–∞–Ω–∏—è", "–±–∏–∑–Ω–µ—Å", "–ø—Ä–æ–µ–∫—Ç"]) else "—Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–π"
        }

    def get_fresh_topic(self, channel_analysis):
        """–ù–∞—Ö–æ–¥–∏—Ç —Å–≤–µ–∂—É—é —Ç–µ–º—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–Ω–∞–ª–∞ –∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤"""
        used_themes = self.history.get("used_themes", [])
        used_keywords = self.history.get("used_keywords", [])
        
        available_themes = channel_analysis["themes"]
        
        theme_counts = {theme: used_themes.count(theme) for theme in available_themes}
        min_count = min(theme_counts.values())
        fresh_themes = [theme for theme, count in theme_counts.items() if count == min_count]
        
        selected_theme = random.choice(fresh_themes)
        
        prompt = f"""
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã –∏ –Ω–æ–≤–æ—Å—Ç–∏ –≤ —Å—Ñ–µ—Ä–µ {selected_theme} –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ 3 —Å–∞–º—ã–µ —Å–≤–µ–∂–∏–µ –∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ —Ç–µ–º—ã –¥–ª—è –ø–æ—Å—Ç–∞ –≤ Telegram. 
        
        –£—á—Ç–∏ —á—Ç–æ –≤ –∫–∞–Ω–∞–ª–µ —É–∂–µ –æ–±—Å—É–∂–¥–∞–ª–∏—Å—å —ç—Ç–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(used_keywords[-5:]) if used_keywords else '–ø–æ–∫–∞ –Ω–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏'}
        
        –ò—â–∏ —Å–∞–º—ã–µ –Ω–æ–≤—ã–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏, –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è –≤ —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏. –¢–µ–º—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∞–∫—Ç—É–∞–ª—å–Ω—ã–º–∏ –∏ –ø–æ–ª–µ–∑–Ω—ã–º–∏.
        
        –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —Ç–µ–º—ã, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ –∑–Ω–∞–∫–æ–º | –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
        """
        
        try:
            response = requests.post(
                f"https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}",
                json={
                    "contents": [{"parts": [{"text": prompt}]}],
                    "generationConfig": {
                        "maxOutputTokens": 300,
                        "temperature": 0.9,
                    }
                },
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                topics_text = data["candidates"][0]["content"]["parts"][0]["text"].strip()
                topics = [t.strip() for t in topics_text.split('|') if t.strip()]
                if topics:
                    return selected_theme, random.choice(topics)
        except:
            pass
        
        # Fallback –µ—Å–ª–∏ API –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ
        fallback_topics = {
            "HR": ["–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∫ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é –∫–æ–º–∞–Ω–¥–æ–π", "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã –º–æ—Ç–∏–≤–∞—Ü–∏–∏", "–¢—Ä–µ–Ω–¥—ã –≤ —Ä–µ–∫—Ä—É—Ç–∏–Ω–≥–µ"],
            "PR": ["–ù–æ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏", "–°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Ä–µ–ø—É—Ç–∞—Ü–∏–∏", "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç-–º–∞—Ä–∫–µ—Ç–∏–Ω–≥"],
            "—Ä–µ–º–æ–Ω—Ç": ["–ò–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–º–æ–Ω—Ç–∞", "–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –≤ –¥–∏–∑–∞–π–Ω–µ"]
        }
        
        topic = random.choice(fallback_topics.get(selected_theme, fallback_topics["HR"]))
        return selected_theme, topic

    def get_time_config(self, time_type):
        configs = {
            "morning": {"min_length": 300, "max_length": 500, "tone": "—ç–Ω–µ—Ä–≥–∏—á–Ω—ã–π, –º–æ—Ç–∏–≤–∏—Ä—É—é—â–∏–π"},
            "afternoon": {"min_length": 600, "max_length": 900, "tone": "–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π, —É–≥–ª—É–±–ª–µ–Ω–Ω—ã–π"},
            "evening": {"min_length": 500, "max_length": 700, "tone": "—Ä–µ—Ñ–ª–µ–∫—Å–∏–≤–Ω—ã–π, –≤–¥–æ—Ö–Ω–æ–≤–ª—è—é—â–∏–π"}
        }
        return configs.get(time_type, configs["morning"])

    def generate_structured_post(self, time_type):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ—Å—Ç –ø–æ —Å—Ç—Ä–æ–≥–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –¥–ª–∏–Ω—ã"""
        
        posts = self.get_channel_posts()
        channel_analysis = self.analyze_channel_content(posts)
        theme, topic = self.get_fresh_topic(channel_analysis)
        config = self.get_time_config(time_type)
        
        structure_prompt = f"""
        –°–û–ó–î–ê–ô –ü–û–°–¢ –î–õ–Ø TELEGRAM –ö–ê–ù–ê–õ–ê –°–¢–†–û–ì–û –ü–û –°–õ–ï–î–£–Æ–©–ï–ô –°–¢–†–£–ö–¢–£–†–ï:

        –¢–ï–ú–ê: {theme}
        –ü–û–î–¢–ï–ú–ê: {topic}
        –°–¢–ò–õ–¨: {config['tone']}
        –î–ò–ê–ü–ê–ó–û–ù –î–õ–ò–ù–´: {config['min_length']}-{config['max_length']} —Å–∏–º–≤–æ–ª–æ–≤ (—Å–æ–±–ª—é–¥–∞–π —Ç–æ—á–Ω–æ!)

        –°–¢–†–£–ö–¢–£–†–ê (—Å–æ–±–ª—é–¥–∞–π —Ç–æ—á–Ω–æ):

        1. –ó–ê–¶–ï–ü–ö–ê (1-2 —Å—Ç—Ä–æ–∫–∏)
        {{—Ü–µ–ø–ª—è—é—â–∞—è —Ñ—Ä–∞–∑–∞, —ç–º–æ—Ü–∏—è, –±–æ–ª—å –∏–ª–∏ –∏–Ω—Ç—Ä–∏–≥–∞}}

        ‚∏ª

        2. –ö–û–ù–¢–ï–ö–°–¢ / –ß–¢–û –°–õ–£–ß–ò–õ–û–°–¨ (1-3 —Å—Ç—Ä–æ–∫–∏)
        {{–æ–ø–∏—Å—ã–≤–∞–µ—à—å —Å—É—Ç—å —Å–∏—Ç—É–∞—Ü–∏–∏}}

        ‚∏ª

        3. –ì–õ–ê–í–ù–ê–Ø –ú–´–°–õ–¨ (–æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)
        {{—Å—É—Ç—å –ø–æ—Å—Ç–∞}}

        ‚∏ª

        4. –ü–û–õ–ï–ó–ù–û–°–¢–¨ (—Ñ–æ—Ä–º–∞—Ç —Å–ø–∏—Å–∫–∞)
        ‚Ä¢ {{–ø—É–Ω–∫—Ç 1}}
        ‚Ä¢ {{–ø—É–Ω–∫—Ç 2}} 
        ‚Ä¢ {{–ø—É–Ω–∫—Ç 3}}
        ‚Ä¢ {{–ø—É–Ω–∫—Ç 4}}

        ‚∏ª

        5. –ö–û–†–û–¢–ö–ò–ô –û–ü–´–¢ / –ú–ò–ù–ò-–ö–ï–ô–° (1-2 —Å—Ç—Ä–æ–∫–∏)
        {{–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä}}

        ‚∏ª

        6. –ò–¢–û–ì / –í–´–í–û–î (–æ–¥–Ω–æ —Å–∏–ª—å–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)
        {{—Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∞–∫—Ü–µ–Ω—Ç}}

        ‚∏ª

        7. –õ–Å–ì–ö–ò–ô CTA (–±–µ–∑ –Ω–∞–ø–æ—Ä–∞)
        {{–≤–æ–ø—Ä–æ—Å / –ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏–µ –∫ –¥–∏–∞–ª–æ–≥—É}}

        –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
        - –°–æ—Ö—Ä–∞–Ω—è–π –í–°–ï —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ "‚∏ª" —Ç–æ—á–Ω–æ –∫–∞–∫ –≤ —à–∞–±–ª–æ–Ω–µ
        - –î–ª–∏–Ω–∞ –ø–æ—Å—Ç–∞ –î–û–õ–ñ–ù–ê –±—ã—Ç—å –æ—Ç {config['min_length']} –¥–æ {config['max_length']} —Å–∏–º–≤–æ–ª–æ–≤
        - –ü–∏—à–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ –¥–ª—è —É–º–Ω–æ–≥–æ –¥—Ä—É–≥–∞
        - –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Ç—Ä–µ–Ω–¥—ã
        - –î–æ–±–∞–≤—å 1-2 —É–º–µ—Å—Ç–Ω—ã—Ö —ç–º–æ–¥–∑–∏ –≤ –∑–∞—Ü–µ–ø–∫—É –∏–ª–∏ CTA
        - –ò–∑–±–µ–≥–∞–π –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –∂–∞—Ä–≥–æ–Ω–∞
        - –°–¥–µ–ª–∞–π —Ç–µ–∫—Å—Ç —Ü–µ–ø–ª—è—é—â–∏–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º
        - –û—Å–Ω–æ–≤—ã–≤–∞–π—Å—è –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø—Ä–∞–∫—Ç–∏–∫–∞—Ö –∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–∞—Ö

        –ö–∞–Ω–∞–ª —É–∂–µ –æ–±—Å—É–∂–¥–∞–ª: {', '.join(channel_analysis['keywords'][:3]) if channel_analysis['keywords'] else '—Ä–∞–∑–Ω—ã–µ —Ç–µ–º—ã'}
        –°–¥–µ–ª–∞–π —ç—Ç–æ—Ç –ø–æ—Å—Ç —Å–≤–µ–∂–∏–º –∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º!
        """
        
        max_attempts = 3
        for attempt in range(max_attempts):
            try:
                response = requests.post(
                    f"https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}",
                    json={
                        "contents": [{"parts": [{"text": structure_prompt}]}],
                        "generationConfig": {
                            "maxOutputTokens": config['max_length'] + 100,
                            "temperature": 0.8,
                        }
                    },
                    timeout=30
                )
                
                if response.status_code == 200:
                    data = response.json()
                    post_text = data["candidates"][0]["content"]["parts"][0]["text"].strip()
                    
                    if (self.is_content_unique(post_text) and 
                        self.validate_structure(post_text) and 
                        self.validate_length(post_text, config)):
                        
                        self.mark_content_used(post_text, theme, topic)
                        return post_text
                    else:
                        continue
                        
            except:
                pass
        
        return None

    def validate_structure(self, post_text):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —á—Ç–æ –ø–æ—Å—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–µ"""
        return post_text.count("‚∏ª") >= 6

    def validate_length(self, post_text, config):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —á—Ç–æ –¥–ª–∏–Ω–∞ –ø–æ—Å—Ç–∞ –≤ –Ω—É–∂–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ"""
        length = len(post_text)
        return config['min_length'] <= length <= config['max_length']

    def is_content_unique(self, content):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        content_hash = hashlib.md5(content.encode()).hexdigest()
        return content_hash not in self.history["post_hashes"]

    def mark_content_used(self, content, theme, topic):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–Ω—Ç–µ"""
        content_hash = hashlib.md5(content.encode()).hexdigest()
        
        self.history["post_hashes"].append(content_hash)
        self.history["used_themes"].append(theme)
        
        keywords = re.findall(r'\b[–∞-—èa-z]{4,}\b', topic.lower())
        self.history["used_keywords"].extend(keywords)
        
        for key in ["post_hashes", "used_themes", "used_keywords"]:
            if len(self.history[key]) > 200:
                self.history[key] = self.history[key][-200:]
        
        self.save_history()

    def send_post(self, post_text):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ—Å—Ç –≤ Telegram"""
        try:
            url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
            payload = {
                "chat_id": CHANNEL_ID,
                "text": post_text,
                "parse_mode": "HTML"
            }
            
            response = requests.post(url, json=payload, timeout=30)
            return response.status_code == 200
        except:
            return False

    def create_and_send_post(self, time_type):
        """–°–æ–∑–¥–∞–µ—Ç –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ—Å—Ç"""
        config = self.get_time_config(time_type)
        print(f"üîÑ –°–æ–∑–¥–∞–Ω–∏–µ {time_type} –ø–æ—Å—Ç–∞ ({config['min_length']}-{config['max_length']} —Å–∏–º–≤–æ–ª–æ–≤)...")
        
        posts = self.get_channel_posts()
        analysis = self.analyze_channel_content(posts)
        print(f"üìä –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ç–µ–º—ã: {', '.join(analysis['themes'])}")
        
        post_text = self.generate_structured_post(time_type)
        
        if post_text:
            success = self.send_post(post_text)
            if success:
                print(f"‚úÖ {time_type.capitalize()} –ø–æ—Å—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω!")
                print(f"üìù –î–ª–∏–Ω–∞: {len(post_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                print(f"üéØ –¢–µ–º–∞: {analysis['themes'][0] if analysis['themes'] else 'HR'}")
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ {time_type} –ø–æ—Å—Ç–∞")
        else:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å {time_type} –ø–æ—Å—Ç")

def morning_post():
    bot = StructuredTelegramPostBot()
    bot.create_and_send_post("morning")

def afternoon_post():
    bot = StructuredTelegramPostBot()
    bot.create_and_send_post("afternoon")

def evening_post():
    bot = StructuredTelegramPostBot()
    bot.create_and_send_post("evening")

def main():
    schedule.every().day.at("09:00").do(morning_post)
    schedule.every().day.at("14:00").do(afternoon_post)
    schedule.every().day.at("19:00").do(evening_post)
    
    print("ü§ñ –£–º–Ω—ã–π –±–æ—Ç –∑–∞–ø—É—â–µ–Ω!")
    print("üéØ –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è: HR, PR, —Ä–µ–º–æ–Ω—Ç –∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ")
    print("üìê –§–æ—Ä–º–∞—Ç: 7-–±–ª–æ—á–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏")
    print("‚è∞ –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ: 09:00 (300-500), 14:00 (600-900), 19:00 (500-700)")
    print("üîç –§—É–Ω–∫—Ü–∏–∏: –∞–≤—Ç–æ-–∞–Ω–∞–ª–∏–∑ –∫–∞–Ω–∞–ª–∞ + –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã + –ø—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏")
    
    while True:
        schedule.run_pending()
        time.sleep(60)

if __name__ == "__main__":
    main()
