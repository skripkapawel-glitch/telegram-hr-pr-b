import os
import requests
import datetime
import hashlib
import json
import random
import re
import time
from difflib import SequenceMatcher
from collections import Counter
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# –§–∞–π–ª –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ö–µ—à–µ–π –ø–æ—Å—Ç–æ–≤
HISTORY_FILE = "post_history.json"

class TelegramPostGenerator:
    def __init__(self):
        self.history = self.load_post_history()
        self.session_start = datetime.datetime.now()
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ç–µ–º—ã –∏ —Ñ–æ—Ä–º–∞—Ç—ã
        self.all_themes = [
            "HR –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª–æ–º", "PR –∏ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏", "—Ä–µ–º–æ–Ω—Ç –∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ",
            "—Ü–∏—Ñ—Ä–æ–≤–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è", "—É–¥–∞–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞", "–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –∫—É–ª—å—Ç—É—Ä–∞",
            "–ª–∏–¥–µ—Ä—Å—Ç–≤–æ –∏ –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç", "–∏–Ω–Ω–æ–≤–∞—Ü–∏–∏ –≤ –±–∏–∑–Ω–µ—Å–µ", "–∫–ª–∏–µ–Ω—Ç—Å–∫–∏–π –æ–ø—ã—Ç",
            "—Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ", "—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞–º–∏", "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∏ –ø—Ä–æ–¥–∞–∂–∏",
            "—Ñ–∏–Ω–∞–Ω—Å—ã –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ AI", "—É—Å—Ç–æ–π—á–∏–≤–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ"
        ]
        
        self.post_formats = [
            "üî• {content}", "üéØ {content}", "üí° {content}", "üöÄ {content}", 
            "ü§Ø {content}", "üíé {content}", "üåü {content}", "üìà {content}",
            "üé® {content}", "‚ö° {content}", "üß† {content}", "üíº {content}"
        ]
        
        self.calls_to_action = [
            "üî• –ü–æ–¥–µ–ª–∏—Å—å —Å –¥—Ä—É–≥–æ–º, –µ—Å–ª–∏ –ø–æ–ª–µ–∑–Ω–æ!",
            "üí¨ –ß—Ç–æ –¥—É–º–∞–µ—à—å? –ù–∞–ø–∏—à–∏ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ö!",
            "üîÑ –†–µ–ø–æ—Å—Ç–Ω–∏, –µ—Å–ª–∏ —Å–æ–≥–ª–∞—Å–µ–Ω!",
            "üë• –ü–æ–∫–∞–∂–∏ –∫–æ–ª–ª–µ–≥–∞–º ‚Äì –æ–±—Å—É–¥–∏–º –≤–º–µ—Å—Ç–µ!",
            "üíé –°–æ—Ö—Ä–∞–Ω–∏ —Å–µ–±–µ –Ω–∞ —Å—Ç–µ–Ω—É!",
            "üöÄ –ü–æ–¥–µ–ª–∏—Å—å –º–Ω–µ–Ω–∏–µ–º –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö!",
            "üìå –°–æ—Ö—Ä–∞–Ω–∏ –¥–ª—è –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏—è!",
            "ü§ù –ü–æ–¥–µ–ª–∏—Å—å –æ–ø—ã—Ç–æ–º –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö!"
        ]

    def load_post_history(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å—Ç–æ–≤"""
        try:
            if os.path.exists(HISTORY_FILE):
                with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, dict):
                        return data
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: {e}")
        
        return {
            "post_hashes": [],
            "used_themes": [],
            "used_formats": [],
            "used_images": [],
            "last_reset_date": datetime.datetime.now().strftime('%Y-%m-%d'),
            "channel_analysis": {
                "common_words": [],
                "recent_themes": [],
                "post_patterns": []
            }
        }

    def save_post_history(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å—Ç–æ–≤"""
        try:
            with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
                json.dump(self.history, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏: {e}")

    def get_telegram_channel_posts(self, limit=50):
        """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –ø–æ—Å—Ç—ã –∏–∑ Telegram –∫–∞–Ω–∞–ª–∞"""
        try:
            url = f"https://api.telegram.org/bot{BOT_TOKEN}/getChatHistory"
            payload = {
                "chat_id": CHANNEL_ID,
                "limit": limit
            }
            
            response = requests.post(url, json=payload, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            posts = []
            
            if data.get("ok") and data.get("result"):
                for message in data["result"]:
                    content = ""
                    if "text" in message:
                        content = message["text"]
                    elif "caption" in message:
                        content = message["caption"]
                    
                    if content and len(content.strip()) > 50:  # –¢–æ–ª—å–∫–æ –∑–Ω–∞—á–∏–º—ã–µ –ø–æ—Å—Ç—ã
                        posts.append({
                            "content": content,
                            "date": message.get("date", ""),
                            "message_id": message.get("message_id")
                        })
            
            print(f"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(posts)} –ø–æ—Å—Ç–æ–≤ –∏–∑ –∫–∞–Ω–∞–ª–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return posts
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å—Ç–æ–≤ –∏–∑ –∫–∞–Ω–∞–ª–∞: {e}")
            return []

    def analyze_channel_content(self, posts):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –∫–∞–Ω–∞–ª–∞ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π"""
        if not posts:
            return {
                "common_words": [],
                "recent_themes": [],
                "avoid_patterns": [],
                "recent_formats": []
            }
        
        # –ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤
        all_text = " ".join([post["content"] for post in posts])
        words = re.findall(r'\b[–∞-—èa-z]{4,}\b', all_text.lower())
        
        # –°—Ç–æ–ø-—Å–ª–æ–≤–∞
        stop_words = {
            '—ç—Ç–æ—Ç', '—ç—Ç–æ', '—Ç–∞–∫–∂–µ', '–æ—á–µ–Ω—å', '–º–æ–∂–Ω–æ', '–±—É–¥–µ—Ç', '–µ—Å—Ç—å', '–µ—Å–ª–∏', '—á—Ç–æ–±—ã',
            '–∫–æ—Ç–æ—Ä—ã–π', '—Ç–æ–ª—å–∫–æ', '–ø–æ—Å–ª–µ', '–∫–æ–≥–¥–∞', '–ø–æ—Ç–æ–º—É', '–º–æ–∂–µ—Ç', '—Å–≤–æ–π', '–≤–∞—à',
            '–Ω–∞—à', '–∏—Ö', '–µ–≥–æ', '–µ—ë', '–∏–º', '–∏–º–∏', '–Ω–∏—Ö', '–Ω–∞–º–∏', '–≤–∞–º–∏', '—Ç–∞–∫–æ–π'
        }
        
        word_freq = Counter([word for word in words if word not in stop_words])
        common_words = [word for word, count in word_freq.most_common(20)]
        
        # –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ä–º–∞—Ç–æ–≤
        recent_formats = []
        for post in posts[:10]:
            content = post["content"]
            if "üî•" in content: recent_formats.append("üî•")
            if "üéØ" in content: recent_formats.append("üéØ")
            if "üí°" in content: recent_formats.append("üí°")
            if "üöÄ" in content: recent_formats.append("üöÄ")
        
        analysis = {
            "common_words": common_words,
            "recent_themes": self.extract_themes(posts),
            "avoid_patterns": self.find_common_patterns(posts),
            "recent_formats": list(set(recent_formats))[:5]
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.history["channel_analysis"] = analysis
        self.save_post_history()
        
        return analysis

    def extract_themes(self, posts):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–º—ã –∏–∑ –ø–æ—Å—Ç–æ–≤"""
        themes = []
        theme_keywords = {
            'hr': ['–ø–µ—Ä—Å–æ–Ω–∞–ª', '—Å–æ—Ç—Ä—É–¥–Ω–∏–∫', '–∫–æ–º–∞–Ω–¥–∞', 'hr', '—Ä–µ–∫—Ä—É—Ç–∏–Ω–≥'],
            'pr': ['–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è', 'pr', '–ø—É–±–ª–∏—á–Ω—ã–π', '–±—Ä–µ–Ω–¥', '—Ä–µ–ø—É—Ç–∞—Ü–∏—è'],
            '—Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ': ['—Ä–µ–º–æ–Ω—Ç', '—Å—Ç—Ä–æ–∏—Ç–µ–ª—å', '–ø—Ä–æ–µ–∫—Ç', '–æ–±—ä–µ–∫—Ç', '—Ä–µ–º–æ–Ω—Ç'],
            '—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ': ['—É–ø—Ä–∞–≤–ª–µ–Ω', '–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç', '–ª–∏–¥–µ—Ä', '—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤'],
            '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏': ['—Ç–µ—Ö–Ω–æ–ª–æ–≥', 'digital', 'ai', '–∏–Ω–Ω–æ–≤–∞—Ü', '–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü']
        }
        
        for post in posts[:15]:
            content_lower = post["content"].lower()
            for theme, keywords in theme_keywords.items():
                if any(keyword in content_lower for keyword in keywords):
                    if theme not in themes:
                        themes.append(theme)
        
        return themes[:5]

    def find_common_patterns(self, posts):
        """–ù–∞—Ö–æ–¥–∏—Ç —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –ø–æ—Å—Ç–∞—Ö"""
        patterns = []
        
        for post in posts[:10]:
            content = post["content"]
            
            # –ü–æ–∏—Å–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Ç–∏–ø–∞ "X —Å–ø–æ—Å–æ–±–æ–≤ —Å–¥–µ–ª–∞—Ç—å Y"
            ways_pattern = re.findall(r'(\d+)\s*(—Å–ø–æ—Å–æ–±|—à–∞–≥|–º–µ—Ç–æ–¥|—Å–æ–≤–µ—Ç)', content.lower())
            if ways_pattern:
                patterns.append("number_ways")
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏
            if '?' in content and any(word in content.lower() for word in ['–∫–∞–∫', '—á—Ç–æ', '–ø–æ—á–µ–º—É', '–∫–æ–≥–¥–∞']):
                patterns.append("question_pattern")
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
            stat_pattern = re.findall(r'(\d+%)', content)
            if stat_pattern:
                patterns.append("statistic_pattern")
        
        return list(set(patterns))

    def calculate_similarity(self, text1, text2):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–µ–∫—Å—Ç–∞–º–∏"""
        return SequenceMatcher(None, text1.lower(), text2.lower()).ratio()

    def is_content_unique(self, content, recent_posts, similarity_threshold=0.65):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        content_hash = hashlib.md5(content.encode()).hexdigest()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Ö–µ—à—É
        if content_hash in self.history["post_hashes"]:
            print("‚ùå –ü–æ—Å—Ç –Ω–µ —É–Ω–∏–∫–∞–ª–µ–Ω: –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ö–µ—à")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å –ª–æ–∫–∞–ª—å–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–µ–π
        for old_hash in self.history["post_hashes"][-20:]:
            if old_hash == content_hash:
                return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –ø–æ—Å—Ç–∞–º–∏ –∏–∑ –∫–∞–Ω–∞–ª–∞
        for post in recent_posts[:15]:
            similarity = self.calculate_similarity(content, post["content"])
            if similarity > similarity_threshold:
                print(f"‚ùå –°—Ö–æ–∂–µ—Å—Ç—å —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –ø–æ—Å—Ç–æ–º: {similarity:.2f}")
                return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
        words = content.split()
        if len(words) < 25:
            print("‚ö†Ô∏è –ü–æ—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π, –Ω–æ –ø—Ä–∏–Ω–∏–º–∞–µ–º")
        
        return True

    def get_unique_theme(self):
        """–í—ã–±–∏—Ä–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—É—é —Ç–µ–º—É"""
        # –ò—Å–∫–ª—é—á–∞–µ–º –Ω–µ–¥–∞–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ–º—ã
        recent_themes = self.history.get("used_themes", [])[-5:]
        available_themes = [theme for theme in self.all_themes if theme not in recent_themes]
        
        if not available_themes:
            available_themes = self.all_themes
        
        selected_theme = random.choice(available_themes)
        return selected_theme

    def get_unique_format(self):
        """–í—ã–±–∏—Ä–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
        recent_formats = self.history.get("used_formats", [])[-3:]
        available_formats = [fmt for fmt in self.post_formats if fmt not in recent_formats]
        
        if not available_formats:
            available_formats = self.post_formats
        
        return random.choice(available_formats)

    def get_unique_image(self, attempt=1):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É"""
        if attempt > 3:
            timestamp = int(time.time() * 1000)
            return f"https://picsum.photos/1200/800?random={timestamp}"
        
        timestamp = int(time.time() * 1000) + attempt
        image_hash = hashlib.md5(str(timestamp).encode()).hexdigest()[:12]
        image_url = f"https://picsum.photos/1200/800?random={image_hash}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–∞—Ä—Ç–∏–Ω–∫–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞—Å—å
        if image_hash not in self.history.get("used_images", [])[-10:]:
            return image_url
        else:
            return self.get_unique_image(attempt + 1)

    def create_ai_prompt(self, theme, time_of_day, channel_analysis, config):
        """–°–æ–∑–¥–∞–µ—Ç —É–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ò–ò —Å —É—á–µ—Ç–æ–º –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–Ω–∞–ª–∞"""
        
        common_words = ", ".join(channel_analysis.get("common_words", [])[:8])
        recent_themes = ", ".join(channel_analysis.get("recent_themes", [])[:3])
        avoid_patterns = channel_analysis.get("avoid_patterns", [])
        recent_formats = ", ".join(channel_analysis.get("recent_formats", [])[:3])
        
        avoid_patterns_text = ""
        if "number_ways" in avoid_patterns:
            avoid_patterns_text += "‚Ä¢ –ò–∑–±–µ–≥–∞–π —à–∞–±–ª–æ–Ω–æ–≤ 'X —Å–ø–æ—Å–æ–±–æ–≤ —Å–¥–µ–ª–∞—Ç—å Y'\n"
        if "question_pattern" in avoid_patterns:
            avoid_patterns_text += "‚Ä¢ –ù–µ –Ω–∞—á–∏–Ω–∞–π —Å –≤–æ–ø—Ä–æ—Å–æ–≤ '–ö–∞–∫ —Å–¥–µ–ª–∞—Ç—å...'\n"
        if "statistic_pattern" in avoid_patterns:
            avoid_patterns_text += "‚Ä¢ –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —à–∞–±–ª–æ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n"
        
        prompt = f"""
–°–û–ó–î–ê–ô –ê–ë–°–û–õ–Æ–¢–ù–û –£–ù–ò–ö–ê–õ–¨–ù–´–ô –í–ò–†–ê–õ–¨–ù–´–ô –ü–û–°–¢ –î–õ–Ø TELEGRAM

–ê–ù–ê–õ–ò–ó –ö–ê–ù–ê–õ–ê –ü–û–ö–ê–ó–ê–õ:
‚Ä¢ –ß–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Å–ª–æ–≤–∞: {common_words}
‚Ä¢ –ù–µ–¥–∞–≤–Ω–∏–µ —Ç–µ–º—ã: {recent_themes}
‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: {recent_formats}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –£–ù–ò–ö–ê–õ–¨–ù–û–°–¢–ò:
1. –ò–ó–ë–ï–ì–ê–ô —ç—Ç–∏—Ö —Å–ª–æ–≤: {common_words}
2. –ù–ï –ò–°–ü–û–õ–¨–ó–£–ô —ç—Ç–∏ —Ç–µ–º—ã: {recent_themes}
3. –°–æ–∑–¥–∞–π –°–û–í–ï–†–®–ï–ù–ù–û –ù–û–í–´–ô –ø–æ–¥—Ö–æ–¥
{avoid_patterns_text}
4. –ò—Å–ø–æ–ª—å–∑—É–π —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ 2024-2025 –≥–æ–¥–∞

–û–°–ù–û–í–ù–ê–Ø –¢–ï–ú–ê: {theme}
–í–†–ï–ú–Ø –°–£–¢–û–ö: {time_of_day}
–¶–ï–õ–ï–í–ê–Ø –î–õ–ò–ù–ê: {config['ideal_length']}-{config['max_tokens']} —Å–∏–º–≤–æ–ª–æ–≤

–°–¢–†–£–ö–¢–£–†–ê (–≤—ã–±–µ—Ä–∏ –ù–û–í–£–Æ):
‚Ä¢ –ü—Ä–æ–±–ª–µ–º–∞ ‚Üí –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ ‚Üí –†–µ—à–µ–Ω–∏–µ ‚Üí –î–µ–π—Å—Ç–≤–∏–µ
‚Ä¢ –¢—Ä–µ–Ω–¥ ‚Üí –ê–Ω–∞–ª–∏–∑ ‚Üí –ö–µ–π—Å ‚Üí –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
‚Ä¢ –ú–∏—Ñ ‚Üí –§–∞–∫—Ç—ã ‚Üí –î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ ‚Üí –í—ã–≤–æ–¥
‚Ä¢ –í—ã–∑–æ–≤ ‚Üí –°—Ç—Ä–∞—Ç–µ–≥–∏—è ‚Üí –†–µ–∑—É–ª—å—Ç–∞—Ç—ã ‚Üí –ò–Ω—Å–∞–π—Ç

–°–¢–ò–õ–¨ –ò –§–û–†–ú–ê–¢:
‚Ä¢ –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–π —è–∑—ã–∫
‚Ä¢ –≠–º–æ–¥–∑–∏ –¥–ª—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∞–∫—Ü–µ–Ω—Ç–∞
‚Ä¢ –ö–æ—Ä–æ—Ç–∫–∏–µ –∞–±–∑–∞—Ü—ã –¥–ª—è —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏
‚Ä¢ –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏ —Ü–∏—Ñ—Ä—ã
‚Ä¢ –ü—Ä–∏–∑—ã–≤ –∫ –æ–±—Å—É–∂–¥–µ–Ω–∏—é

–ü–†–ò–ú–ï–†–´ –£–ù–ò–ö–ê–õ–¨–ù–´–• –£–ì–õ–û–í:
–í–º–µ—Å—Ç–æ "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è" ‚Üí "–ù–µ–π—Ä–æ–ª–∏–Ω–≥–≤–∏—Å—Ç–∏–∫–∞: –∫–∞–∫ —Å–ª–æ–≤–∞ –º–µ–Ω—è—é—Ç —Ö–∏–º–∏—é –º–æ–∑–≥–∞ –≤ –ø–µ—Ä–µ–≥–æ–≤–æ—Ä–∞—Ö"
–í–º–µ—Å—Ç–æ "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥–æ–π" ‚Üí "–ë–∏–æ–º–∏–º–µ—Ç–∏–∫–∞ –ª–∏–¥–µ—Ä—Å—Ç–≤–∞: —á–µ–º—É –±–∏–∑–Ω–µ—Å –º–æ–∂–µ—Ç –Ω–∞—É—á–∏—Ç—å—Å—è —É –ø—Ä–∏—Ä–æ–¥—ã"

–ö–û–ù–¢–†–û–õ–¨–ù–´–ô –°–ü–ò–°–û–ö –£–ù–ò–ö–ê–õ–¨–ù–û–°–¢–ò:
‚ñ° –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ª–∏ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞?
‚ñ° –ü–æ—Ö–æ–∂ –ª–∏ –ø–æ–¥—Ö–æ–¥ –Ω–∞ –Ω–µ–¥–∞–≤–Ω–∏–µ –ø–æ—Å—Ç—ã?
‚ñ° –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ —Å–≤–µ–∂–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è?
‚ñ° –í—ã–∑—ã–≤–∞–µ—Ç –ª–∏ –ø–æ—Å—Ç –∏—Å–∫—Ä–µ–Ω–Ω–∏–π –∏–Ω—Ç–µ—Ä–µ—Å?

–¶–ï–õ–¨: –°–æ–∑–¥–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–º –∑–∞—Ö–æ—á–µ—Ç—Å—è –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ!
"""

        return prompt

    def generate_post_content(self, time_of_day, attempt=1):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ—Å—Ç–∞"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–∞–Ω–∞–ª–∞
            channel_posts = self.get_telegram_channel_posts(limit=50)
            channel_analysis = self.analyze_channel_content(channel_posts)
            
            # –û—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–∏ –Ω–æ–≤–æ–º –¥–Ω–µ
            current_date = datetime.datetime.now().strftime('%Y-%m-%d')
            if self.history.get("last_reset_date") != current_date:
                self.history["used_formats"] = []
                self.history["used_themes"] = []
                self.history["last_reset_date"] = current_date
                self.save_post_history()
                print("üîÑ –ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞ (–Ω–æ–≤—ã–π –¥–µ–Ω—å)")
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª–∏–Ω—ã
            length_config = {
                "morning": {"max_tokens": 600, "ideal_length": 400},
                "afternoon": {"max_tokens": 1200, "ideal_length": 800}, 
                "evening": {"max_tokens": 500, "ideal_length": 300}
            }
            config = length_config.get(time_of_day, length_config["afternoon"])
            
            # –í—ã–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ–º—É –∏ —Ñ–æ—Ä–º–∞—Ç
            theme = self.get_unique_theme()
            post_format = self.get_unique_format()
            call_to_action = random.choice(self.calls_to_action)
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç
            prompt = self.create_ai_prompt(theme, time_of_day, channel_analysis, config)
            
            print(f"üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–∞ ({theme})... –ü–æ–ø—ã—Ç–∫–∞ {attempt}")
            print(f"üéØ –ò–∑–±–µ–≥–∞–µ–º: {', '.join(channel_analysis.get('common_words', [])[:3])}")
            
            # –ó–∞–ø—Ä–æ—Å –∫ Gemini API
            response = requests.post(
                f"https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}",
                json={
                    "contents": [{"parts": [{"text": prompt}]}],
                    "generationConfig": {
                        "maxOutputTokens": config["max_tokens"],
                        "temperature": 0.95,
                        "topP": 0.9,
                        "topK": 50
                    }
                },
                timeout=60
            )
            
            if response.status_code == 200:
                data = response.json()
                post_text = data["candidates"][0]["content"]["parts"][0]["text"].strip()
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–∑—ã–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é
                post_text += f"\n\n{call_to_action}"
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å
                if self.is_content_unique(post_text, channel_posts):
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    formatted_text = post_format.format(content=post_text)
                    image_url = self.get_unique_image()
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
                    self.mark_post_used(post_text, theme, post_format, image_url)
                    
                    print(f"‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –ø–æ—Å—Ç —Å–æ–∑–¥–∞–Ω! ({len(post_text)} —Å–∏–º–≤–æ–ª–æ–≤)")
                    return formatted_text, image_url, theme
                else:
                    print(f"üîÑ –ü–æ—Å—Ç –Ω–µ —É–Ω–∏–∫–∞–ª–µ–Ω, –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞... ({attempt}/3)")
                    if attempt < 3:
                        return self.generate_post_content(time_of_day, attempt + 1)
                    else:
                        return self.get_emergency_post(channel_analysis)
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ API: {response.status_code}")
                raise Exception(f"API error: {response.status_code}")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            if attempt < 2:
                return self.generate_post_content(time_of_day, attempt + 1)
            else:
                return self.get_emergency_post({})

    def mark_post_used(self, content, theme, post_format, image_url):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ—Å—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é"""
        content_hash = hashlib.md5(content.encode()).hexdigest()
        image_hash = hashlib.md5(image_url.encode()).hexdigest()
        
        self.history["post_hashes"].append(content_hash)
        self.history["used_images"].append(image_hash)
        
        if theme not in self.history["used_themes"]:
            self.history["used_themes"].append(theme)
        
        if post_format not in self.history["used_formats"]:
            self.history["used_formats"].append(post_format)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏
        for key in ["post_hashes", "used_themes", "used_formats", "used_images"]:
            if key in self.history and len(self.history[key]) > 500:
                self.history[key] = self.history[key][-500:]
        
        self.save_post_history()

    def get_emergency_post(self, channel_analysis):
        """–°–æ–∑–¥–∞–µ—Ç –∞–≤–∞—Ä–∏–π–Ω—ã–π —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –ø–æ—Å—Ç"""
        timestamp = datetime.datetime.now().strftime('%H:%M:%S')
        unique_id = hashlib.md5(timestamp.encode()).hexdigest()[:8]
        
        emergency_posts = [
            f"""üöÄ <b>–≠–ö–°–ö–õ–Æ–ó–ò–í: –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω—Å–∞–π—Ç {timestamp}</b>

–ù–æ–≤–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç: –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –≤–æ–∑—Ä–∞—Å—Ç–∞–µ—Ç –Ω–∞ 73% –ø—Ä–∏ —Å–º–µ–Ω–µ –ø–æ–¥—Ö–æ–¥–æ–≤!

üí° <b>–§–∞–∫—Ç:</b> –ö–∞–∂–¥–∞—è —É–Ω–∏–∫–∞–ª—å–Ω–∞—è –∏–¥–µ—è —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–≤—è–∑—å.
üéØ <b>–î–µ–π—Å—Ç–≤–∏–µ:</b> –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–µ–≥–æ–¥–Ω—è —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–∞–±–æ—Ç–µ.

üî• <b>–†–µ–∑—É–ª—å—Ç–∞—Ç –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω!</b>

#{unique_id} #–£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å""",

            f"""üíé <b>–ú–û–ú–ï–ù–¢ –ò–°–¢–ò–ù–´: {datetime.datetime.now().strftime('%d.%m')}</b>

–°–µ–∫—Ä–µ—Ç —É—Å–ø–µ—Ö–∞: –≤ 2025 –≥–æ–¥—É —Ü–µ–Ω–Ω–æ—Å—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤—ã—Ä–æ—Å–ª–∞ –Ω–∞ 240%!

üåü <b>–¢—Ä–µ–Ω–¥:</b> –ê—É–¥–∏—Ç–æ—Ä–∏—è –∂–∞–∂–¥–µ—Ç —Å–≤–µ–∂–∏—Ö –∏–¥–µ–π –∏ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π.
üß† <b>–ò–Ω—Å–∞–π—Ç:</b> –°–∞–º—ã–µ –≤–∏—Ä–∞–ª—å–Ω—ã–µ –ø–æ—Å—Ç—ã –Ω–∞—Ä—É—à–∞—é—Ç —à–∞–±–ª–æ–Ω—ã.

üí¨ <b>–ß—Ç–æ –≤–∞—Å —Å–µ–≥–æ–¥–Ω—è —É–¥–∏–≤–∏–ª–æ?</b>

#{unique_id} #–ù–æ–≤—ã–µ–ì–æ—Ä–∏–∑–æ–Ω—Ç—ã""",

            f"""üé® <b>–¢–í–û–†–ß–ï–°–ö–ò–ô –ü–†–û–†–´–í: –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å</b>

–í—Ä–µ–º—è: {timestamp}
–°—Ç–∞—Ç—É—Å: –°–æ–∑–¥–∞–Ω–æ 100% —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç

‚ö° <b>–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è:</b> –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ + —Å–≤–µ–∂–∏–π –≤–∑–≥–ª—è–¥ = –≤–∏—Ä–∞–ª—å–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç
üìà <b>–†–µ–∑—É–ª—å—Ç–∞—Ç:</b> –≠—Ç–æ—Ç –ø–æ—Å—Ç –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏

üîÆ <b>–ë—É–¥—É—â–µ–µ –∑–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ —Ä–µ—à–µ–Ω–∏—è–º–∏!</b>

#{unique_id} #–≠–∫—Å–∫–ª—é–∑–∏–≤"""
        ]
        
        theme = "–≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è —É–Ω–∏–∫–∞–ª—å–Ω–∞—è —Ç–µ–º–∞"
        post_format = random.choice(self.post_formats)
        post_text = random.choice(emergency_posts)
        image_url = self.get_unique_image()
        
        self.mark_post_used(post_text, theme, post_format, image_url)
        
        return post_text, image_url, theme

    def send_to_telegram(self, message, image_url=None):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ—Å—Ç –≤ Telegram"""
        try:
            if image_url:
                url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendPhoto"
                payload = {
                    "chat_id": CHANNEL_ID,
                    "photo": image_url,
                    "caption": message,
                    "parse_mode": "HTML"
                }
            else:
                url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
                payload = {
                    "chat_id": CHANNEL_ID,
                    "text": message,
                    "parse_mode": "HTML"
                }
            
            response = requests.post(url, json=payload, timeout=30)
            response.raise_for_status()
            
            print("‚úÖ –ü–æ—Å—Ç —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ Telegram!")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {e}")
            return False

    def run(self):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞"""
        try:
            now = datetime.datetime.now()
            current_hour = now.hour
            
            print(f"\n{'='*60}")
            print(f"üöÄ –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –ø–æ—Å—Ç–æ–≤")
            print(f"üìÖ {now.strftime('%d.%m.%Y %H:%M:%S')}")
            print(f"{'='*60}")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ä–µ–º—è —Å—É—Ç–æ–∫
            time_mapping = {
                6: "morning",   # 9:00 –ú–°–ö
                11: "afternoon", # 14:00 –ú–°–ö  
                16: "evening"    # 19:00 –ú–°–ö
            }
            time_of_day = time_mapping.get(current_hour, "afternoon")
            
            print(f"üéØ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è {time_of_day} –ø–æ—Å—Ç–∞...")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ—Å—Ç
            post_text, image_url, theme = self.generate_post_content(time_of_day)
            
            print(f"üìù –¢–µ–º–∞: {theme}")
            print(f"üìä –î–ª–∏–Ω–∞: {len(post_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"üñºÔ∏è –ö–∞—Ä—Ç–∏–Ω–∫–∞: {image_url}")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Telegram
            success = self.send_to_telegram(post_text, image_url)
            
            if success:
                print("‚úÖ –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
                print(f"üîê –•–µ—à –ø–æ—Å—Ç–∞: {hashlib.md5(post_text.encode()).hexdigest()[:12]}")
            else:
                print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –ø–æ—Å—Ç–∞")
            
            print(f"{'='*60}\n")
            
        except Exception as e:
            print(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()

def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""
    generator = TelegramPostGenerator()
    generator.run()

if __name__ == "__main__":
    main()
