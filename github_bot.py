import os
import requests
import random
import json
import time
import logging
import re
import sys
from datetime import datetime, timedelta
from urllib.parse import quote_plus

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
BOT_TOKEN = os.environ.get("BOT_TOKEN")
MAIN_CHANNEL_ID = os.environ.get("CHANNEL_ID", "@da4a_hr")
ZEN_CHANNEL_ID = "@tehdzenm"
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
if not BOT_TOKEN:
    logger.error("‚ùå BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
    print("‚ùå BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
    sys.exit(1)

if not GEMINI_API_KEY:
    logger.error("‚ùå GEMINI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
    print("‚ùå GEMINI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
    sys.exit(1)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–µ—Å—Å–∏–∏ requests
session = requests.Session()
session.headers.update({
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Accept': 'application/json, text/plain, */*',
    'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
})

print("=" * 80)
print("üöÄ GITHUB BOT: –ì–ï–ù–ï–†–ê–¶–ò–Ø –ü–û–°–¢–û–í (Telegram + –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω)")
print("=" * 80)
print(f"üîë BOT_TOKEN: {'‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω' if BOT_TOKEN else '‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}")
print(f"üîë GEMINI_API_KEY: {'‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω' if GEMINI_API_KEY else '‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}")
print(f"üì¢ –û—Å–Ω–æ–≤–Ω–æ–π –∫–∞–Ω–∞–ª (Telegram): {MAIN_CHANNEL_ID}")
print(f"üì¢ –í—Ç–æ—Ä–æ–π –∫–∞–Ω–∞–ª (Telegram –¥–ª—è –î–∑–µ–Ω): {ZEN_CHANNEL_ID}")
print("=" * 80)

class AIPostGenerator:
    def __init__(self):
        self.themes = ["HR –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª–æ–º", "PR –∏ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏", "—Ä–µ–º–æ–Ω—Ç –∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ"]
        self.prohibited_topics = ["—É–¥–∞–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞", "–≥–∏–±—Ä–∏–¥–Ω–∞—è —Ä–∞–±–æ—Ç–∞", "–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø–æ –¢–ö"]
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        self.theme_keywords = {
            "HR –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª–æ–º": {
                "keywords_en": ["human resources", "recruitment", "office", "teamwork", "meeting", 
                               "business", "workplace", "interview", "corporate", "leadership",
                               "training", "employees", "collaboration", "professional", "career",
                               "manager", "staff", "workshop", "conference", "presentation"],
                "keywords_ru": ["–∫–∞–¥—Ä—ã", "—Ä–µ–∫—Ä—É—Ç–∏–Ω–≥", "–æ—Ñ–∏—Å", "–∫–æ–º–∞–Ω–¥–∞", "—Å–æ–≤–µ—â–∞–Ω–∏–µ",
                               "–±–∏–∑–Ω–µ—Å", "—Ä–∞–±–æ—á–µ–µ –º–µ—Å—Ç–æ", "—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ", "–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π", "–ª–∏–¥–µ—Ä—Å—Ç–≤–æ",
                               "–æ–±—É—á–µ–Ω–∏–µ", "—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏", "—Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–æ", "–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª", "–∫–∞—Ä—å–µ—Ä–∞"],
                "required_words": ["office", "business", "team", "work", "professional"],
                "forbidden_words": ["home", "family", "leisure", "vacation", "sport", "nature", "art"]
            },
            "PR –∏ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏": {
                "keywords_en": ["public relations", "media", "communication", "marketing", "brand",
                               "social media", "networking", "press", "journalist", "campaign",
                               "strategy", "advertising", "digital", "content", "influencer",
                               "presentation", "event", "conference", "speaker", "audience"],
                "keywords_ru": ["–ø–∏–∞—Ä", "—Å–º–∏", "–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏", "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥", "–±—Ä–µ–Ω–¥",
                               "—Å–æ—Ü—Å–µ—Ç–∏", "–Ω–µ—Ç–≤–æ—Ä–∫–∏–Ω–≥", "–ø—Ä–µ—Å—Å–∞", "–∂—É—Ä–Ω–∞–ª–∏—Å—Ç", "–∫–∞–º–ø–∞–Ω–∏—è",
                               "—Å—Ç—Ä–∞—Ç–µ–≥–∏—è", "—Ä–µ–∫–ª–∞–º–∞", "—Ü–∏—Ñ—Ä–æ–≤–æ–π", "–∫–æ–Ω—Ç–µ–Ω—Ç", "–∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä"],
                "required_words": ["media", "communication", "public", "marketing", "digital"],
                "forbidden_words": ["sport", "music", "food", "travel", "fashion", "beauty"]
            },
            "—Ä–µ–º–æ–Ω—Ç –∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ": {
                "keywords_en": ["construction", "renovation", "tools", "building", "repair",
                               "worker", "contractor", "hardhat", "equipment", "site",
                               "architecture", "design", "interior", "home improvement", "handyman",
                               "plumbing", "electrical", "carpentry", "painting", "renovation"],
                "keywords_ru": ["—Å—Ç—Ä–æ–π–∫–∞", "—Ä–µ–º–æ–Ω—Ç", "–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã", "–∑–¥–∞–Ω–∏–µ", "–ø–æ—á–∏–Ω–∫–∞",
                               "—Ä–∞–±–æ—á–∏–π", "–ø–æ–¥—Ä—è–¥—á–∏–∫", "–∫–∞—Å–∫–∞", "–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ", "–ø–ª–æ—â–∞–¥–∫–∞",
                               "–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞", "–¥–∏–∑–∞–π–Ω", "–∏–Ω—Ç–µ—Ä—å–µ—Ä", "–æ–±—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–æ–º–∞", "–º–∞—Å—Ç–µ—Ä"],
                "required_words": ["construction", "building", "tools", "worker", "renovation"],
                "forbidden_words": ["nature", "sky", "clouds", "sunset", "sunrise", "landscape",
                                   "mountain", "ocean", "beach", "forest", "park", "garden",
                                   "animal", "wildlife", "flower", "tree", "water"]
            }
        }
        
        self.history_file = "post_history.json"
        self.post_history = self.load_post_history()
        self.current_theme = None
        
        self.time_slots = {
            "09:00": {
                "type": "morning",
                "name": "–£—Ç—Ä–µ–Ω–Ω–∏–π –ø–æ—Å—Ç",
                "emoji": "üåÖ",
                "tg_chars": (400, 600),
                "zen_chars": (600, 800),
                "tg_style": "–∂–∏–≤–æ–π, –¥–∏–Ω–∞–º–∏—á–Ω—ã–π, —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π, –º–Ω–æ–≥–æ —ç–º–æ–¥–∑–∏",
                "zen_style": "–≥–ª—É–±–∂–µ, –∞–Ω–∞–ª–∏—Ç–∏—á–Ω–µ–µ, –∫–∞–∫ –º–∏–Ω–∏-—Å—Ç–∞—Ç—å—è. –ë–µ–∑ —ç–º–æ–¥–∑–∏",
                "content_type": "–ª–µ–≥–∫–∏–π –±–æ–¥—Ä—è—â–∏–π –∏–Ω—Å–∞–π—Ç, –º–∏–Ω–∏-–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ, 1-2 –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–æ–≤–µ—Ç–∞"
            },
            "14:00": {
                "type": "day",
                "name": "–î–Ω–µ–≤–Ω–æ–π –ø–æ—Å—Ç",
                "emoji": "üåû",
                "tg_chars": (700, 900),
                "zen_chars": (700, 900),
                "tg_style": "–∂–∏–≤–æ–π, –¥–∏–Ω–∞–º–∏—á–Ω—ã–π, —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π, –º–Ω–æ–≥–æ —ç–º–æ–¥–∑–∏",
                "zen_style": "–≥–ª—É–±–∂–µ, –∞–Ω–∞–ª–∏—Ç–∏—á–Ω–µ–µ, –∫–∞–∫ –º–∏–Ω–∏-—Å—Ç–∞—Ç—å—è. –ë–µ–∑ —ç–º–æ–¥–∑–∏",
                "content_type": "–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–±–æ—Ä —Å–∏—Ç—É–∞—Ü–∏–∏, –º–∏–Ω–∏-–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å —Ü–∏—Ñ—Ä–∞–º–∏"
            },
            "19:00": {
                "type": "evening",
                "name": "–í–µ—á–µ—Ä–Ω–∏–π –ø–æ—Å—Ç",
                "emoji": "üåô",
                "tg_chars": (600, 900),
                "zen_chars": (600, 700),
                "tg_style": "–∂–∏–≤–æ–π, –¥–∏–Ω–∞–º–∏—á–Ω—ã–π, —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π, –º–Ω–æ–≥–æ —ç–º–æ–¥–∑–∏",
                "zen_style": "–≥–ª—É–±–∂–µ, –∞–Ω–∞–ª–∏—Ç–∏—á–Ω–µ–µ, –∫–∞–∫ –º–∏–Ω–∏-—Å—Ç–∞—Ç—å—è. –ë–µ–∑ —ç–º–æ–¥–∑–∏",
                "content_type": "–º–∏–Ω–∏-–∏—Å—Ç–æ—Ä–∏—è —Å –º–æ—Ä–∞–ª—å—é, –º–Ω–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–∞ + –º—è–≥–∫–∞—è —ç–º–æ—Ü–∏—è"
            }
        }

    def load_post_history(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å—Ç–æ–≤"""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return {
                "posts": {},
                "themes": {},
                "last_post_time": None,
                "last_slots": [],
                "image_queries": {}
            }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: {e}")
            return {
                "posts": {},
                "themes": {},
                "last_post_time": None,
                "last_slots": [],
                "image_queries": {}
            }

    def save_post_history(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å—Ç–æ–≤"""
        try:
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(self.post_history, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏: {e}")

    def get_smart_theme(self):
        """–í—ã–±–∏—Ä–∞–µ—Ç —Ç–µ–º—É"""
        try:
            themes_history = self.post_history.get("themes", {}).get("global", [])
            available_themes = self.themes.copy()
            
            for theme in themes_history[-2:]:
                if theme in available_themes:
                    available_themes.remove(theme)
            
            if not available_themes:
                available_themes = self.themes.copy()
            
            theme = random.choice(available_themes)
            
            if "themes" not in self.post_history:
                self.post_history["themes"] = {}
            if "global" not in self.post_history["themes"]:
                self.post_history["themes"]["global"] = []
            
            self.post_history["themes"]["global"].append(theme)
            if len(self.post_history["themes"]["global"]) > 10:
                self.post_history["themes"]["global"] = self.post_history["themes"]["global"][-8:]
            
            self.save_post_history()
            logger.info(f"üéØ –í—ã–±—Ä–∞–Ω–∞ —Ç–µ–º–∞: {theme}")
            return theme
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–±–æ—Ä–∞ —Ç–µ–º—ã: {e}")
            return random.choice(self.themes)

    def create_combined_prompt(self, theme, time_slot_info, time_key):
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è Gemini"""
        slot_name = time_slot_info['name']
        content_type = time_slot_info['content_type']
        tg_chars_min, tg_chars_max = time_slot_info['tg_chars']
        zen_chars_min, zen_chars_max = time_slot_info['zen_chars']
        
        prompt = f"""–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –≤ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å 30+ –ª–µ—Ç –æ–ø—ã—Ç–∞. –°–æ–∑–¥–∞–π 2 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–∞ –Ω–∞ —Ç–µ–º—É: {theme}

–í–†–ï–ú–Ø: {time_key} ({slot_name})
–¢–ò–ü –ö–û–ù–¢–ï–ù–¢–ê: {content_type}
–ó–ê–ü–†–ï–©–ï–ù–ù–´–ï –¢–ï–ú–´: {', '.join(self.prohibited_topics)} ‚Äî –ù–ò–ö–û–ì–î–ê –ù–ï –£–ü–û–ú–ò–ù–ê–¢–¨!

‚∏ª
–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö TELEGRAM –ü–û–°–¢–£ ({tg_chars_min}-{tg_chars_max} —Å–∏–º–≤–æ–ª–æ–≤):

1. –ò–°–¢–û–†–ò–ò/–†–ê–°–°–ö–ê–ó–´:
   ‚Ä¢ –•—É–∫ ‚Üí –†–∞—Å—Å–∫–∞–∑ (–æ–±—ã—á–Ω—ã–º–∏ –∞–±–∑–∞—Ü–∞–º–∏) ‚Üí –ú–æ—Ä–∞–ª—å ‚Üí –í–æ–ø—Ä–æ—Å
   
2. –°–ü–ò–°–ö–ò/–ü–ï–†–ï–ß–ò–°–õ–ï–ù–ò–Ø:
   ‚Ä¢ –•—É–∫ ‚Üí –ü—É–Ω–∫—Ç—ã (—Å —Ç–æ—á–∫–∞–º–∏ ‚Ä¢) ‚Üí –í—ã–≤–æ–¥ ‚Üí –í–æ–ø—Ä–æ—Å

–í–ê–ñ–ù–û: –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ—á–∫–∏ ‚Ä¢ –≤ –∏—Å—Ç–æ—Ä–∏—è—Ö!

–û–ë–©–ò–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
‚Ä¢ –°—Ç–∏–ª—å: –∂–∏–≤–æ–π, –¥–∏–Ω–∞–º–∏—á–Ω—ã–π, —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π
‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –≤ —Ö—É–∫–µ –∏ –≤ –∫–æ–Ω—Ü–µ
‚Ä¢ 3-6 —Ö–µ—à—Ç–µ–≥–æ–≤ –≤ –∫–æ–Ω—Ü–µ
‚Ä¢ –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å –¥–ª—è –æ–±—Å—É–∂–¥–µ–Ω–∏—è

‚∏ª
–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –Ø–ù–î–ï–ö–°.–î–ó–ï–ù –ü–û–°–¢–£ ({zen_chars_min}-{zen_chars_max} —Å–∏–º–≤–æ–ª–æ–≤):

–°–¢–†–£–ö–¢–£–†–ê:
‚Ä¢ –•–£–ö: 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –±–µ–∑ —ç–º–æ–¥–∑–∏
‚Ä¢ –û–°–ù–û–í–ù–û–ô –¢–ï–ö–°–¢: –∞–±–∑–∞—Ü—ã –±–µ–∑ –æ—Ç—Å—Ç—É–ø–æ–≤
‚Ä¢ –§–ê–ö–¢–´ –∏–ª–∏ –¶–ò–§–†–´
‚Ä¢ –í–´–í–û–î: —á–µ—Ç–∫–∏–µ –≤—ã–≤–æ–¥—ã
‚Ä¢ –ó–ê–ö–†–´–í–ê–®–ö–ê: –≤–æ–≤–ª–µ–∫–∞—é—â–∏–π –≤–æ–ø—Ä–æ—Å
‚Ä¢ –•–ï–®–¢–ï–ì–ò: 3-6 —Ö–µ—à—Ç–µ–≥–æ–≤ –≤ –∫–æ–Ω—Ü–µ

–°–¢–ò–õ–¨:
‚Ä¢ –ì–ª—É–±–æ–∫–∏–π, –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π, –∫–∞–∫ –º–∏–Ω–∏-—Å—Ç–∞—Ç—å—è
‚Ä¢ –ë–ï–ó –≠–ú–û–î–ó–ò: –Ω–∏–∫–∞–∫–∏—Ö —Å–º–∞–π–ª–∏–∫–æ–≤
‚Ä¢ –ß–µ—Ç–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏ –ª–æ–≥–∏–∫–∞
‚Ä¢ –≠–∫—Å–ø–µ—Ä—Ç–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ —Ñ–∞–∫—Ç—ã –∏ –ø—Ä–∏–º–µ—Ä—ã

‚∏ª
–í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
‚Ä¢ Telegram: {tg_chars_min}-{tg_chars_max} —Å–∏–º–≤–æ–ª–æ–≤
‚Ä¢ –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω: {zen_chars_min}-{zen_chars_max} —Å–∏–º–≤–æ–ª–æ–≤
‚Ä¢ –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω –ù–ò–ö–û–ì–î–ê –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç {zen_chars_max} —Å–∏–º–≤–æ–ª–æ–≤!
‚Ä¢ –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω: –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´ —Ö–µ—à—Ç–µ–≥–∏ –∏ –∑–∞–∫—Ä—ã–≤–∞—à–∫–∞

‚∏ª
–ü–û–ò–°–ö–û–í–´–ô –ó–ê–ü–†–û–° –î–õ–Ø –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø:

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—É—Ç—å –ø–æ—Å—Ç–∞ –∏ —Å–æ–∑–¥–∞–π 2 —Ä–∞–∑–Ω—ã—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ –¥–ª—è —Ñ–æ—Ç–æ–±–∞–Ω–∫–∞ Pexels.com

–¢–ï–ú–ê–¢–ò–ö–ê: {theme}
–¢–†–ï–ë–û–í–ê–ù–ò–Ø –î–õ–Ø –ó–ê–ü–†–û–°–û–í:
1. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –ø–æ—Å—Ç—É
2. –ò—Å–ø–æ–ª—å–∑—É–π –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –ø–æ—Å—Ç–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º
3. 4-7 —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –∏ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
4. –†–∞–∑–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è Telegram –∏ –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω
5. –ú–∏–Ω–∏–º—É–º 3 –æ–±—â–∏—Ö —Å–ª–æ–≤–∞ —Å —Ç–µ–º–∞—Ç–∏–∫–æ–π

–ü–†–ò–ú–ï–†–´ –î–õ–Ø –ö–ê–ñ–î–û–ô –¢–ï–ú–´:
‚Ä¢ HR: "office meeting business team collaboration professional"
‚Ä¢ PR: "media communication conference presentation public relations"
‚Ä¢ –†–µ–º–æ–Ω—Ç: "construction workers building site renovation tools"

–§–û–†–ú–ê–¢: —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –∏ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é

–°–æ–∑–¥–∞–π 2 –†–ê–ó–ù–´–• —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞: –¥–ª—è Telegram –∏ –¥–ª—è –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω

‚∏ª
–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (–¢–û–ß–ù–û!):

Telegram-–ø–æ—Å—Ç:
[–¢–µ–∫—Å—Ç –¥–ª—è Telegram]

–Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω-–ø–æ—Å—Ç:
[–¢–µ–∫—Å—Ç –¥–ª—è –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω]

–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è Telegram –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:
[–ó–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, 4-7 —Å–ª–æ–≤, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –ø–æ—Å—Ç—É]

–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:
[–ó–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, 4-7 —Å–ª–æ–≤, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –ø–æ—Å—Ç—É]

‚∏ª
–ù–ê–ß–ò–ù–ê–ô –ì–ï–ù–ï–†–ê–¶–ò–Æ –°–ï–ô–ß–ê–°!"""

        return prompt

    def test_gemini_access(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø –∫ Gemini API"""
        try:
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"
            
            test_data = {
                "contents": [{"parts": [{"text": "Test"}]}],
                "generationConfig": {"maxOutputTokens": 5}
            }
            
            response = session.post(url, json=test_data, timeout=10)
            if response.status_code == 200:
                logger.info("‚úÖ Gemini –¥–æ—Å—Ç—É–ø–µ–Ω")
                return True
            return False
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ Gemini: {e}")
            return False

    def test_bot_access(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø –±–æ—Ç–∞"""
        try:
            response = session.get(f"https://api.telegram.org/bot{BOT_TOKEN}/getMe", timeout=10)
            return response.status_code == 200
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–∞: {e}")
            return False

    def generate_with_gemini(self, prompt, max_retries=3):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ Gemini"""
        for attempt in range(max_retries):
            try:
                url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"
                
                data = {
                    "contents": [{"parts": [{"text": prompt}]}],
                    "generationConfig": {
                        "temperature": 0.85,
                        "maxOutputTokens": 3500,
                        "topP": 0.92,
                        "topK": 35
                    }
                }
                
                logger.info(f"üîÑ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})...")
                
                response = session.post(url, json=data, timeout=60)
                
                if response.status_code == 200:
                    result = response.json()
                    if 'candidates' in result and result['candidates']:
                        generated_text = result['candidates'][0]['content']['parts'][0]['text']
                        
                        total_length = len(generated_text)
                        logger.info(f"üìÑ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {total_length} —Å–∏–º–≤–æ–ª–æ–≤")
                        
                        if "Telegram-–ø–æ—Å—Ç:" in generated_text and "–Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω-–ø–æ—Å—Ç:" in generated_text:
                            logger.info(f"‚úÖ –¢–µ–∫—Å—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")
                            return generated_text.strip()
                        else:
                            logger.warning(f"‚ö†Ô∏è –ù–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞...")
                            time.sleep(2)
                            continue
                    else:
                        logger.warning("‚ö†Ô∏è Gemini –Ω–µ –≤–µ—Ä–Ω—É–ª —Ç–µ–∫—Å—Ç, –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞...")
                        time.sleep(2)
                        continue
                        
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
                if attempt < max_retries - 1:
                    time.sleep(3)
        
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç")
        return None

    def split_text_and_queries(self, combined_text):
        """–†–∞–∑–¥–µ–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ Telegram, –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω –∏ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã"""
        if not combined_text:
            return None, None, None, None
        
        tg_query = None
        zen_query = None
        
        # –ò—â–µ–º –∑–∞–ø—Ä–æ—Å—ã
        if "–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è Telegram –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:" in combined_text:
            tg_part = combined_text.split("–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è Telegram –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:")[1]
            if "–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:" in tg_part:
                tg_query = tg_part.split("–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:")[0]
            else:
                tg_query = tg_part
            tg_query = tg_query.strip().split('\n')[0].strip()
        
        if "–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:" in combined_text:
            zen_part = combined_text.split("–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:")[1]
            zen_query = zen_part.strip().split('\n')[0].strip()
        
        # –£–±–∏—Ä–∞–µ–º –∑–∞–ø—Ä–æ—Å—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞
        for marker in ["–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è Telegram –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:", "–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:"]:
            if marker in combined_text:
                combined_text = combined_text.split(marker)[0]
        
        # –ò—â–µ–º –ø–æ—Å—Ç—ã
        tg_start = combined_text.find("Telegram-–ø–æ—Å—Ç:")
        zen_start = combined_text.find("–Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω-–ø–æ—Å—Ç:")
        
        if tg_start != -1 and zen_start != -1:
            tg_part = combined_text[tg_start:zen_start]
            tg_text = tg_part.replace("Telegram-–ø–æ—Å—Ç:", "").strip()
            
            zen_part = combined_text[zen_start:]
            zen_text = zen_part.replace("–Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω-–ø–æ—Å—Ç:", "").strip()
            
            return tg_text, zen_text, tg_query, zen_query
        
        return None, None, tg_query, zen_query

    def analyze_post_content(self, text, theme):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ø–æ—Å—Ç–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        text_lower = text.lower()
        theme_info = self.theme_keywords.get(theme, {})
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞
        found_keywords = []
        for keyword in theme_info.get('keywords_ru', []):
            if keyword in text_lower:
                found_keywords.append(keyword)
        
        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –º–∞–ª–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤, –¥–æ–±–∞–≤–ª—è–µ–º —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ
        if len(found_keywords) < 3:
            found_keywords.extend(random.sample(theme_info.get('keywords_ru', [])[:10], 3))
        
        return list(set(found_keywords))[:5]

    def enhance_image_query(self, query, theme, post_text):
        """–£–ª—É—á—à–∞–µ—Ç –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –ø–æ—Å—Ç–∞"""
        if not query or query == "None":
            return self.create_enhanced_query(theme, post_text)
        
        theme_info = self.theme_keywords.get(theme, {})
        
        # –û—á–∏—â–∞–µ–º –∑–∞–ø—Ä–æ—Å
        query = query.lower().strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤ –¥–ª—è —Ç–µ–º—ã
        for required_word in theme_info.get('required_words', []):
            if required_word not in query:
                # –î–æ–±–∞–≤–ª—è–µ–º 1-2 –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤–∞
                query_words = query.split(',')
                query_words.append(required_word)
                query = ', '.join(list(set(query_words))[:7])
        
        # –£–±–∏—Ä–∞–µ–º –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞
        for forbidden_word in theme_info.get('forbidden_words', []):
            query = re.sub(r'\b' + re.escape(forbidden_word) + r'\b', '', query, flags=re.IGNORECASE)
        
        # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö –∑–∞–ø—è—Ç—ã—Ö
        query = re.sub(r',\s*,+', ', ', query)
        query = re.sub(r'^\s*,|\s*,\s*$', '', query)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
        if len(query.split(',')) < 5:
            extra_keywords = random.sample(theme_info.get('keywords_en', [])[:15], 2)
            query += ', ' + ', '.join([kw for kw in extra_keywords if kw not in query])
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        words = [w.strip() for w in query.split(',') if w.strip()]
        words = list(set(words))[:7]  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞, –º–∞–∫—Å 7
        
        return ', '.join(words)

    def create_enhanced_query(self, theme, post_text):
        """–°–æ–∑–¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–º—ã –∏ —Ç–µ–∫—Å—Ç–∞"""
        theme_info = self.theme_keywords.get(theme, {})
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
        post_keywords = self.analyze_post_content(post_text, theme)
        
        # –ë–∞–∑–æ–≤—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Ç–µ–º—ã
        base_keywords = random.sample(theme_info.get('keywords_en', [])[:10], 4)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
        required_keywords = theme_info.get('required_words', [])[:2]
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º
        all_keywords = list(set(base_keywords + required_keywords))
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ä—É—Å—Å–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç)
        keyword_translation = {
            "–∫–∞–¥—Ä—ã": "human resources",
            "—Ä–µ–∫—Ä—É—Ç–∏–Ω–≥": "recruitment",
            "–æ—Ñ–∏—Å": "office",
            "–∫–æ–º–∞–Ω–¥–∞": "team",
            "—Å–æ–≤–µ—â–∞–Ω–∏–µ": "meeting",
            "–ø–∏–∞—Ä": "public relations",
            "—Å–º–∏": "media",
            "–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏": "communication",
            "—Å—Ç—Ä–æ–π–∫–∞": "construction",
            "—Ä–µ–º–æ–Ω—Ç": "renovation",
            "–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã": "tools"
        }
        
        for ru_keyword in post_keywords[:2]:
            if ru_keyword in keyword_translation:
                all_keywords.append(keyword_translation[ru_keyword])
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º
        all_keywords = list(set(all_keywords))[:6]
        
        return ', '.join(all_keywords)

    def search_pexels_image(self, search_query, theme, post_text, width=1200, height=630):
        """–ò—â–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ Pexels"""
        try:
            # –£–ª—É—á—à–∞–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –ø–æ—Å—Ç–∞
            enhanced_query = self.enhance_image_query(search_query, theme, post_text)
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π API –∫–ª—é—á Pexels
            PEXELS_API_KEY = "563492ad6f91700001000001d15a5e2d6a9d4b5c8c0e6f5b8c1a9b7c"
            
            encoded_query = quote_plus(enhanced_query)
            url = f"https://api.pexels.com/v1/search?query={encoded_query}&per_page=15&orientation=landscape"
            
            headers = {
                "Authorization": PEXELS_API_KEY,
                "User-Agent": "Mozilla/5.0"
            }
            
            logger.info(f"üîç Pexels –ø–æ–∏—Å–∫: '{enhanced_query}' –¥–ª—è —Ç–µ–º—ã '{theme}'")
            
            response = session.get(url, headers=headers, timeout=15)
            
            if response.status_code == 200:
                data = response.json()
                if data.get('photos') and len(data['photos']) > 0:
                    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–º–µ
                    relevant_photos = self.filter_relevant_photos(data['photos'], theme, enhanced_query)
                    
                    if relevant_photos:
                        # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–µ–µ —Ñ–æ—Ç–æ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                        best_photo = self.select_best_photo(relevant_photos, theme, enhanced_query)
                        image_url = best_photo['src']['large']
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É—Å–ø–µ—à–Ω—ã–π –∑–∞–ø—Ä–æ—Å –≤ –∏—Å—Ç–æ—Ä–∏—é
                        self.save_successful_query(theme, enhanced_query)
                        
                        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
                        return image_url
                    else:
                        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö, –±–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ
                        photo = data['photos'][0]
                        image_url = photo['src']['large']
                        logger.info(f"‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
                        return image_url
                else:
                    logger.warning(f"‚ö†Ô∏è Pexels –Ω–µ –Ω–∞—à–µ–ª —Ñ–æ—Ç–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{enhanced_query}'")
                    return self.get_smart_fallback_image(theme, enhanced_query, width, height)
            else:
                logger.warning(f"‚ö†Ô∏è Pexels API –æ—à–∏–±–∫–∞: {response.status_code}")
                return self.get_smart_fallback_image(theme, enhanced_query, width, height)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –Ω–∞ Pexels: {e}")
            return self.get_smart_fallback_image(theme, search_query, width, height)

    def filter_relevant_photos(self, photos, theme, query):
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–º–µ –∏ –∑–∞–ø—Ä–æ—Å—É"""
        if not photos:
            return photos
        
        theme_info = self.theme_keywords.get(theme, {})
        query_words = set([w.strip().lower() for w in query.split(',')])
        
        relevant_photos = []
        
        for photo in photos:
            photo_description = (photo.get('alt') or photo.get('photographer') or '').lower()
            photo_url = photo.get('url', '').lower()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–ª–æ–≤ –∑–∞–ø—Ä–æ—Å–∞
            query_match_score = sum(1 for word in query_words if word in photo_description or word in photo_url)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
            has_required = all(req_word in photo_description for req_word in theme_info.get('required_words', [])[:2])
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞
            has_forbidden = any(forb_word in photo_description for forb_word in theme_info.get('forbidden_words', []))
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            theme_match_score = sum(1 for keyword in theme_info.get('keywords_en', [])[:10] 
                                  if keyword in photo_description)
            
            # –û–±—â–∏–π —Å—á–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            total_score = query_match_score * 3 + theme_match_score * 2
            
            if has_required and not has_forbidden and total_score > 2:
                photo['relevance_score'] = total_score
                relevant_photos.append(photo)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        relevant_photos.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)
        
        return relevant_photos

    def select_best_photo(self, photos, theme, query):
        """–í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–µ–µ —Ñ–æ—Ç–æ –∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö"""
        if not photos:
            return None
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ñ–æ—Ç–æ —Å –≤—ã—Å–æ–∫–∏–º —Å–∫–æ—Ä–æ–º, –±–µ—Ä–µ–º –µ–≥–æ
        for photo in photos:
            if photo.get('relevance_score', 0) > 5:
                return photo
        
        # –ò–Ω–∞—á–µ –≤—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ –∏–∑ —Ç–æ–ø-3
        top_photos = photos[:3]
        return random.choice(top_photos)

    def save_successful_query(self, theme, query):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —É—Å–ø–µ—à–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        if "image_queries" not in self.post_history:
            self.post_history["image_queries"] = {}
        
        if theme not in self.post_history["image_queries"]:
            self.post_history["image_queries"][theme] = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –µ—Å–ª–∏ –µ–≥–æ –µ—â–µ –Ω–µ—Ç
        if query not in self.post_history["image_queries"][theme]:
            self.post_history["image_queries"][theme].append(query)
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
            if len(self.post_history["image_queries"][theme]) > 20:
                self.post_history["image_queries"][theme] = self.post_history["image_queries"][theme][-20:]
            
            self.save_post_history()

    def get_smart_fallback_image(self, theme, query, width=1200, height=630):
        """–£–º–Ω—ã–π –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ –±–æ–ª–µ–µ –æ–±—â–µ–º—É –∑–∞–ø—Ä–æ—Å—É
            theme_info = self.theme_keywords.get(theme, {})
            general_keywords = theme_info.get('keywords_en', [])[:5]
            general_query = ', '.join(general_keywords)
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            saved_queries = self.post_history.get("image_queries", {}).get(theme, [])
            if saved_queries:
                saved_query = random.choice(saved_queries)
                PEXELS_API_KEY = "563492ad6f91700001000001d15a5e2d6a9d4b5c8c0e6f5b8c1a9b7c"
                encoded_query = quote_plus(saved_query)
                url = f"https://api.pexels.com/v1/search?query={encoded_query}&per_page=5&orientation=landscape"
                
                headers = {"Authorization": PEXELS_API_KEY}
                response = session.get(url, headers=headers, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    if data.get('photos'):
                        photo = random.choice(data['photos'])
                        return photo['src']['large']
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å Unsplash
            unsplash_themes = {
                "HR –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª–æ–º": ["office", "business", "meeting", "workplace"],
                "PR –∏ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏": ["communication", "media", "marketing", "presentation"],
                "—Ä–µ–º–æ–Ω—Ç –∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ": ["construction", "tools", "building", "renovation"]
            }
            
            unsplash_theme = random.choice(unsplash_themes.get(theme, ["business", "work"]))
            return f"https://source.unsplash.com/featured/{width}x{height}/?{unsplash_theme}"
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ fallback: {e}")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å Picsum
            pic_ids = {
                "HR –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª–æ–º": [21, 22, 23, 24, 25],  # –û—Ñ–∏—Å, —Å–æ–≤–µ—â–∞–Ω–∏—è
                "PR –∏ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏": [31, 32, 33, 34, 35],  # –ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏, –º–µ–¥–∏–∞
                "—Ä–µ–º–æ–Ω—Ç –∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ": [11, 12, 13, 14, 15]  # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, —Å—Ç—Ä–æ–π–∫–∞
            }
            
            pic_id_list = pic_ids.get(theme, [1, 2, 3, 4, 5])
            pic_id = random.choice(pic_id_list)
            
            return f"https://picsum.photos/id/{pic_id}/{width}/{height}"

    def format_telegram_text(self, text):
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è Telegram"""
        if not text:
            return ""
        
        # –û—á–∏—â–∞–µ–º HTML —Ç–µ–≥–∏
        text = re.sub(r'<[^>]+>', '', text)
        
        # –ó–∞–º–µ–Ω—è–µ–º HTML —Å—É—â–Ω–æ—Å—Ç–∏
        replacements = {
            '&nbsp;': ' ', '&emsp;': '    ', '¬†': ' ', 
            '**': '', '__': '', '&amp;': '&', '&lt;': '<',
            '&gt;': '>', '&quot;': '"', '&#39;': "'"
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ —Ç–µ–º—ã
        text = self.check_prohibited_topics(text)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ—Å—Ç–∞
        lines = text.split('\n')
        text_lower = text.lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∏—Å—Ç–æ—Ä–∏—é
        is_story = any(keyword in text_lower for keyword in [
            '–∏—Å—Ç–æ—Ä–∏—è', '—Å–ª—É—á–∞–π', '–ø—Ä–∏–º–µ—Ä', '—Å–∏—Ç—É–∞—Ü–∏—è', '–æ–ø—ã—Ç',
            '–æ–¥–Ω–∞–∂–¥—ã', '–∫–∞–∫-—Ç–æ —Ä–∞–∑', '–≤ –æ–¥–∏–Ω –¥–µ–Ω—å', '–Ω–µ–¥–∞–≤–Ω–æ'
        ])
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º
        formatted_lines = []
        in_list = False
        
        for line in lines:
            line = line.strip()
            if not line:
                formatted_lines.append('')
                in_list = False
                continue
            
            # –ï—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫ (–ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ) –∏ –ù–ï –∏—Å—Ç–æ—Ä–∏—è
            if line.startswith('‚Ä¢') and not is_story:
                # –£–±–∏—Ä–∞–µ–º —ç–º–æ–¥–∑–∏ –∏–∑ –ø—É–Ω–∫—Ç–æ–≤ —Å–ø–∏—Å–∫–∞
                line = re.sub(r'^‚Ä¢\s*[üéØ‚è∞ü§îüí°üî•üôà‚≠êüìåüëâ‚ùó‚ö†Ô∏èüõÅüõ†Ô∏èü§¶‚Äç‚ôÇÔ∏è]+\s*', '', line)
                formatted_lines.append("            ‚Ä¢ " + line[1:].strip())
                in_list = True
            # –ï—Å–ª–∏ –∏—Å—Ç–æ—Ä–∏—è —Å —Ç–æ—á–∫–∞–º–∏ - —É–±–∏—Ä–∞–µ–º —Ç–æ—á–∫–∏
            elif line.startswith('‚Ä¢') and is_story:
                line_content = line[1:].strip()
                line_content = re.sub(r'^[üéØ‚è∞ü§îüí°üî•üôà‚≠êüìåüëâ‚ùó‚ö†Ô∏èüõÅüõ†Ô∏èü§¶‚Äç‚ôÇÔ∏è]+\s*', '', line_content)
                formatted_lines.append(line_content)
                in_list = False
            else:
                formatted_lines.append(line)
                in_list = False
        
        formatted_text = '\n'.join(formatted_lines)
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        formatted_text = re.sub(r'\n{3,}', '\n\n', formatted_text)
        
        # –£–±–∏—Ä–∞–µ–º –¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
        formatted_text = re.sub(r'  +', ' ', formatted_text)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ö–µ—à—Ç–µ–≥–∏ –µ—Å–ª–∏ –Ω–µ—Ç
        hashtag_count = len(re.findall(r'#\w+', formatted_text))
        if hashtag_count < 3:
            formatted_text = self.add_telegram_hashtags(formatted_text, self.current_theme)
        
        return formatted_text.strip()

    def format_zen_text(self, text):
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω"""
        if not text:
            return ""
        
        # –û—á–∏—â–∞–µ–º HTML —Ç–µ–≥–∏
        text = re.sub(r'<[^>]+>', '', text)
        
        # –ó–∞–º–µ–Ω—è–µ–º HTML —Å—É—â–Ω–æ—Å—Ç–∏
        replacements = {
            '&nbsp;': ' ', '&emsp;': '    ', '¬†': ' ', 
            '**': '', '__': '', '&amp;': '&', '&lt;': '<',
            '&gt;': '>', '&quot;': '"', '&#39;': "'"
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ —Ç–µ–º—ã
        text = self.check_prohibited_topics(text)
        
        # –£–±–∏—Ä–∞–µ–º —ç–º–æ–¥–∑–∏
        emoji_pattern = re.compile("["
            u"\U0001F600-\U0001F64F"  # emoticons
            u"\U0001F300-\U0001F5FF"  # symbols & pictographs
            u"\U0001F680-\U0001F6FF"  # transport & map symbols
            u"\U0001F1E0-\U0001F1FF"  # flags
            "]+", flags=re.UNICODE)
        text = emoji_pattern.sub(r'', text)
        
        # –£–±–∏—Ä–∞–µ–º –æ—Ç—Å—Ç—É–ø—ã –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫
        lines = []
        for line in text.split('\n'):
            line = line.strip()
            if line:
                lines.append(line)
        
        formatted_text = '\n\n'.join(lines)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ö–µ—à—Ç–µ–≥–∏ –µ—Å–ª–∏ –Ω–µ—Ç
        hashtag_count = len(re.findall(r'#\w+', formatted_text))
        if hashtag_count < 3:
            formatted_text = self.add_zen_hashtags(formatted_text, self.current_theme)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∑–∞–∫—Ä—ã–≤–∞—à–∫–∏
        if not self.has_closing_hook(formatted_text):
            formatted_text = self.add_closing_hook(formatted_text, is_telegram=False)
        
        return formatted_text.strip()

    def check_prohibited_topics(self, text):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ —Ç–µ–º—ã"""
        text_lower = text.lower()
        
        for topic in self.prohibited_topics:
            if topic in text_lower:
                logger.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω–∞—è —Ç–µ–º–∞: {topic}")
                if "—É–¥–∞–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞" in text_lower:
                    text = re.sub(r'—É–¥–∞–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞', '—Ñ–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã', text, flags=re.IGNORECASE)
                if "–≥–∏–±—Ä–∏–¥–Ω–∞—è —Ä–∞–±–æ—Ç–∞" in text_lower:
                    text = re.sub(r'–≥–∏–±—Ä–∏–¥–Ω–∞—è —Ä–∞–±–æ—Ç–∞', '—Å–º–µ—à–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç', text, flags=re.IGNORECASE)
                if "–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø–æ —Ç–∫" in text_lower:
                    text = re.sub(r'–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø–æ —Ç–∫', '–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤', text, flags=re.IGNORECASE)
        
        return text

    def has_closing_hook(self, text):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∑–∞–∫—Ä—ã–≤–∞—à–∫–∏"""
        text_lower = text[-150:].lower() if len(text) > 150 else text.lower()
        hook_indicators = [
            '–∫–∞–∫ –≤—ã —Å—á–∏—Ç–∞–µ—Ç–µ', '—á—Ç–æ –¥—É–º–∞–µ—Ç–µ', '–≤–∞—à–µ –º–Ω–µ–Ω–∏–µ',
            '–ø–∏—à–∏—Ç–µ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö', '–æ–±—Å—É–¥–∏–º', '—Ä–∞—Å—Å–∫–∞–∂–∏—Ç–µ',
            '–ø–æ–¥–µ–ª–∏—Ç–µ—Å—å', '–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ', '–∂–¥—É –≤–∞—à–∏ –º—ã—Å–ª–∏',
            '–∞ —É –≤–∞—Å', '—Å—Ç–∞–ª–∫–∏–≤–∞–ª–∏—Å—å', '–∫–∞–∫–æ–π –ø–æ–¥—Ö–æ–¥'
        ]
        return any(indicator in text_lower for indicator in hook_indicators)

    def add_closing_hook(self, text, is_telegram=True):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–∫—Ä—ã–≤–∞—à–∫—É"""
        if is_telegram:
            hooks = [
                "\n\n–ö–∞–∫ –≤—ã —Å—á–∏—Ç–∞–µ—Ç–µ? –ñ–¥—É –≤–∞—à–∏ –º—ã—Å–ª–∏ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö! üí¨",
                "\n\n–ê —É –≤–∞—Å –±—ã–ª –ø–æ—Ö–æ–∂–∏–π –æ–ø—ã—Ç? –†–∞—Å—Å–∫–∞–∂–∏—Ç–µ! ‚ú®",
                "\n\n–ö–∞–∫–æ–π –ø–æ–¥—Ö–æ–¥ –±–ª–∏–∂–µ –≤–∞–º? –û–±—Å—É–¥–∏–º! üëá"
            ]
        else:
            hooks = [
                "\n\n–ß—Ç–æ –¥—É–º–∞–µ—Ç–µ –ø–æ —ç—Ç–æ–º—É –ø–æ–≤–æ–¥—É? –ü–æ–¥–µ–ª–∏—Ç–µ—Å—å –º–Ω–µ–Ω–∏–µ–º –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö.",
                "\n\n–ê –∫–∞–∫ –≤—ã —Ä–µ—à–∞–µ—Ç–µ –ø–æ–¥–æ–±–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –≤ —Å–≤–æ–µ–π –ø—Ä–∞–∫—Ç–∏–∫–µ?",
                "\n\n–°—Ç–∞–ª–∫–∏–≤–∞–ª–∏—Å—å –ª–∏ –≤—ã —Å —Ç–∞–∫–æ–π —Å–∏—Ç—É–∞—Ü–∏–µ–π? –ö–∞–∫ –ø–æ—Å—Ç—É–ø–∞–ª–∏?"
            ]
        
        hook = random.choice(hooks)
        return text.rstrip() + hook

    def add_telegram_hashtags(self, text, theme):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ö–µ—à—Ç–µ–≥–∏ –¥–ª—è Telegram"""
        theme_hashtags = {
            "HR –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª–æ–º": ["#HR", "#—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ", "#–ø–µ—Ä—Å–æ–Ω–∞–ª", "#–∫–∞—Ä—å–µ—Ä–∞", "#—Ä–∞–±–æ—Ç–∞", "#–∫–æ–º–∞–Ω–¥–∞"],
            "PR –∏ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏": ["#PR", "#–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏", "#–º–∞—Ä–∫–µ—Ç–∏–Ω–≥", "#–±—Ä–µ–Ω–¥", "#–ø–∏–∞—Ä", "#–º–µ–¥–∏–∞"],
            "—Ä–µ–º–æ–Ω—Ç –∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ": ["#—Ä–µ–º–æ–Ω—Ç", "#—Å—Ç—Ä–æ–π–∫–∞", "#–¥–∏–∑–∞–π–Ω", "#–¥–æ–º", "#–∏–Ω—Ç–µ—Ä—å–µ—Ä", "#–æ—Ç–¥–µ–ª–∫–∞"]
        }
        
        base_hashtags = theme_hashtags.get(theme, ["#–∫–æ–Ω—Ç–µ–Ω—Ç", "#—ç–∫—Å–ø–µ—Ä—Ç", "#—Å–æ–≤–µ—Ç—ã", "#–±–∏–∑–Ω–µ—Å"])
        general_hashtags = ["#–∏–Ω—Å–∞–π—Ç—ã", "#–ª–∞–π—Ñ—Ö–∞–∫", "#–ø—Ä–æ—Ñ–µ—Å—Å–∏—è", "#—Ä–∞–∑–≤–∏—Ç–∏–µ"]
        random.shuffle(general_hashtags)
        
        all_hashtags = base_hashtags[:4] + general_hashtags[:2]
        hashtags_to_add = random.sample(all_hashtags, min(5, len(all_hashtags)))
        
        hashtags_line = " ".join(hashtags_to_add)
        return f"{text}\n\n{hashtags_line}"

    def add_zen_hashtags(self, text, theme):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ö–µ—à—Ç–µ–≥–∏ –¥–ª—è –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω"""
        theme_hashtags = {
            "HR –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª–æ–º": ["#HR", "#—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ", "#–ø–µ—Ä—Å–æ–Ω–∞–ª", "#–∫–∞—Ä—å–µ—Ä–∞", "#—Ä–∞–±–æ—Ç–∞"],
            "PR –∏ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏": ["#PR", "#–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏", "#–º–∞—Ä–∫–µ—Ç–∏–Ω–≥", "#–±—Ä–µ–Ω–¥", "#–ø–∏–∞—Ä"],
            "—Ä–µ–º–æ–Ω—Ç –∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ": ["#—Ä–µ–º–æ–Ω—Ç", "#—Å—Ç—Ä–æ–π–∫–∞", "#–¥–∏–∑–∞–π–Ω", "#–¥–æ–º", "#–∏–Ω—Ç–µ—Ä—å–µ—Ä"]
        }
        
        base_hashtags = theme_hashtags.get(theme, ["#–∫–æ–Ω—Ç–µ–Ω—Ç", "#—ç–∫—Å–ø–µ—Ä—Ç", "#—Å–æ–≤–µ—Ç—ã"])
        general_hashtags = ["#–∏–Ω—Å–∞–π—Ç—ã", "#–ø—Ä–æ—Ñ–µ—Å—Å–∏—è", "#—Ä–∞–∑–≤–∏—Ç–∏–µ", "#–±–∏–∑–Ω–µ—Å"]
        random.shuffle(general_hashtags)
        
        all_hashtags = base_hashtags[:4] + general_hashtags[:2]
        hashtags_to_add = random.sample(all_hashtags, min(5, len(all_hashtags)))
        
        hashtags_line = " ".join(hashtags_to_add)
        return f"{text}\n\n{hashtags_line}"

    def check_length_and_fix(self, text, max_length, is_telegram=True):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–ª–∏–Ω—É –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –µ—Å–ª–∏ –Ω—É–∂–Ω–æ"""
        current_len = len(text)
        
        if current_len <= max_length:
            return text
        
        logger.warning(f"‚ö†Ô∏è –¢–µ–∫—Å—Ç –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç ({current_len} > {max_length}), —Å–æ–∫—Ä–∞—â–∞—é...")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ö–µ—à—Ç–µ–≥–∏
        hashtags_match = re.search(r'(#\w+\s*)+$', text)
        hashtags = hashtags_match.group(0) if hashtags_match else ""
        text_without_hashtags = text[:hashtags_match.start()] if hashtags_match else text
        
        # –°–æ–∫—Ä–∞—â–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
        target_length = max_length - len(hashtags) - 20
        
        if len(text_without_hashtags) <= target_length:
            result = text_without_hashtags + ("\n\n" + hashtags if hashtags else "")
        else:
            # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Ö–æ—Ä–æ—à–µ–µ –º–µ—Å—Ç–æ –¥–ª—è –æ–±—Ä–µ–∑–∫–∏
            truncated = text_without_hashtags[:target_length]
            
            last_period = truncated.rfind('.')
            last_question = truncated.rfind('?')
            last_exclamation = truncated.rfind('!')
            last_newline = truncated.rfind('\n')
            
            best_cut = max(last_period, last_question, last_exclamation, last_newline)
            
            if best_cut > target_length * 0.7:
                result = text_without_hashtags[:best_cut + 1].strip()
            else:
                result = text_without_hashtags[:target_length - 3].strip() + "..."
            
            if hashtags:
                result += "\n\n" + hashtags
        
        logger.info(f"üìä –ü–æ—Å–ª–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è: {len(result)} —Å–∏–º–≤–æ–ª–æ–≤")
        return result

    def send_single_post(self, chat_id, text, image_url, is_telegram=True):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ—Å—Ç"""
        try:
            max_length = 1024
            
            if len(text) > max_length:
                text = self.check_length_and_fix(text, max_length, is_telegram)
            
            if not image_url or not image_url.startswith('http'):
                logger.error(f"‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_url}")
                return False
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è Pexels –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if 'pexels.com' in image_url and '?' not in image_url:
                image_url += '?auto=compress&cs=tinysrgb&w=1200&h=630&fit=crop'
            
            params = {
                'chat_id': chat_id,
                'photo': image_url,
                'caption': text,
                'parse_mode': 'HTML',
                'disable_notification': False
            }
            
            logger.info(f"üì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ—Å—Ç –≤ {chat_id}")
            
            response = session.post(
                f"https://api.telegram.org/bot{BOT_TOKEN}/sendPhoto",
                params=params,
                timeout=30
            )
            
            if response.status_code == 200:
                logger.info(f"‚úÖ –ü–æ—Å—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ {chat_id}")
                logger.info(f"üìä –î–ª–∏–Ω–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                logger.info(f"üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_url}")
                return True
            else:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {response.status_code}")
                if response.text:
                    logger.error(f"‚ùå –û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞: {response.text}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")
            return False

    def get_moscow_time(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Ä–µ–º—è –ø–æ –ú–æ—Å–∫–≤–µ"""
        utc_now = datetime.utcnow()
        return utc_now + timedelta(hours=3)

    def generate_and_send_posts(self):
        """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
        try:
            if not self.test_bot_access():
                logger.error("‚ùå –ü—Ä–æ–±–ª–µ–º—ã —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –±–æ—Ç—É")
                return False
            
            if not self.test_gemini_access():
                logger.error("‚ùå Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                return False
            
            now = self.get_moscow_time()
            
            if 5 <= now.hour < 12:
                time_key = "09:00"
                schedule_time = "09:00"
            elif 12 <= now.hour < 17:
                time_key = "14:00"
                schedule_time = "14:00"
            else:
                time_key = "19:00"
                schedule_time = "19:00"
            
            time_slot_info = self.time_slots[time_key]
            
            logger.info(f"üïí –ó–∞–ø—É—Å–∫: {schedule_time} –ú–°–ö")
            logger.info(f"üìù –¢–∏–ø: {time_slot_info['name']}")
            
            self.current_theme = self.get_smart_theme()
            logger.info(f"üéØ –¢–µ–º–∞: {self.current_theme}")
            
            combined_prompt = self.create_combined_prompt(self.current_theme, time_slot_info, time_key)
            logger.info(f"üìù –î–ª–∏–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞: {len(combined_prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            combined_text = self.generate_with_gemini(combined_prompt)
            
            if not combined_text:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å—Ç—ã")
                return False
            
            tg_text, zen_text, tg_image_query, zen_image_query = self.split_text_and_queries(combined_text)
            
            if not tg_text or not zen_text:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–¥–µ–ª–∏—Ç—å —Ç–µ–∫—Å—Ç—ã")
                return False
            
            tg_text = self.format_telegram_text(tg_text)
            zen_text = self.format_zen_text(zen_text)
            
            tg_len = len(tg_text)
            zen_len = len(zen_text)
            tg_min, tg_max = time_slot_info['tg_chars']
            zen_min, zen_max = time_slot_info['zen_chars']
            
            logger.info(f"üìä Telegram: {tg_len} —Å–∏–º–≤–æ–ª–æ–≤ (–¥–∏–∞–ø–∞–∑–æ–Ω: {tg_min}-{tg_max})")
            logger.info(f"üìä –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω: {zen_len} —Å–∏–º–≤–æ–ª–æ–≤ (–¥–∏–∞–ø–∞–∑–æ–Ω: {zen_min}-{zen_max})")
            
            if tg_len > tg_max:
                tg_text = self.check_length_and_fix(tg_text, tg_max, True)
                tg_len = len(tg_text)
                logger.info(f"üìä Telegram –ø–æ—Å–ª–µ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏: {tg_len} —Å–∏–º–≤–æ–ª–æ–≤")
            
            if zen_len > zen_max:
                zen_text = self.check_length_and_fix(zen_text, zen_max, False)
                zen_len = len(zen_text)
                logger.info(f"üìä –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω –ø–æ—Å–ª–µ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏: {zen_len} —Å–∏–º–≤–æ–ª–æ–≤")
            
            logger.info("üñºÔ∏è –ò—â–µ–º –†–ï–õ–ï–í–ê–ù–¢–ù–´–ï —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
            
            # –î–ª—è Telegram - —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
            tg_image_url = self.search_pexels_image(tg_image_query, self.current_theme, tg_text)
            logger.info(f"üîç Telegram –∑–∞–ø—Ä–æ—Å: {tg_image_query}")
            
            time.sleep(1)
            
            # –î–ª—è –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω - —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
            zen_image_url = self.search_pexels_image(zen_image_query, self.current_theme, zen_text)
            logger.info(f"üîç –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω –∑–∞–ø—Ä–æ—Å: {zen_image_query}")
            
            if not tg_image_url or not zen_image_url:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                return False
            
            logger.info("üì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ—Å—Ç—ã...")
            success_count = 0
            
            # Telegram
            logger.info(f"  ‚Üí Telegram: {MAIN_CHANNEL_ID}")
            if self.send_single_post(MAIN_CHANNEL_ID, tg_text, tg_image_url, is_telegram=True):
                success_count += 1
            
            time.sleep(2)
            
            # –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω
            logger.info(f"  ‚Üí –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω: {ZEN_CHANNEL_ID}")
            if self.send_single_post(ZEN_CHANNEL_ID, zen_text, zen_image_url, is_telegram=False):
                success_count += 1
            
            if success_count == 2:
                slot_info = {
                    "date": now.strftime("%Y-%m-%d"),
                    "slot": schedule_time,
                    "theme": self.current_theme,
                    "telegram_length": tg_len,
                    "zen_length": zen_len,
                    "telegram_image_query": tg_image_query,
                    "zen_image_query": zen_image_query,
                    "telegram_enhanced_query": self.enhance_image_query(tg_image_query, self.current_theme, tg_text),
                    "zen_enhanced_query": self.enhance_image_query(zen_image_query, self.current_theme, zen_text),
                    "time": now.strftime("%H:%M:%S")
                }
                
                if "last_slots" not in self.post_history:
                    self.post_history["last_slots"] = []
                
                self.post_history["last_slots"].append(slot_info)
                if len(self.post_history["last_slots"]) > 10:
                    self.post_history["last_slots"] = self.post_history["last_slots"][-10:]
                
                self.post_history["last_post_time"] = now.isoformat()
                self.save_post_history()
                
                logger.info("\n" + "=" * 60)
                logger.info("üéâ –£–°–ü–ï–•! –ü–æ—Å—Ç—ã –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã!")
                logger.info("=" * 60)
                logger.info(f"   üïí –í—Ä–µ–º—è: {schedule_time} –ú–°–ö")
                logger.info(f"   üéØ –¢–µ–º–∞: {self.current_theme}")
                logger.info(f"   üìä Telegram: {tg_len} —Å–∏–º–≤–æ–ª–æ–≤")
                logger.info(f"   üìä –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω: {zen_len} —Å–∏–º–≤–æ–ª–æ–≤")
                logger.info(f"   üñºÔ∏è Telegram –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ: {tg_image_query}")
                logger.info(f"   üñºÔ∏è –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ: {zen_image_query}")
                logger.info("=" * 60)
                return True
            else:
                logger.error(f"‚ùå –û—Ç–ø—Ä–∞–≤–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å. –£—Å–ø–µ—à–Ω–æ: {success_count}/2")
                return False
            
        except Exception as e:
            logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("\n" + "=" * 80)
    print("ü§ñ GITHUB BOT: –ì–ï–ù–ï–†–ê–¶–ò–Ø –ü–û–°–¢–û–í –° –†–ï–õ–ï–í–ê–ù–¢–ù–´–ú–ò –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø–ú–ò")
    print("=" * 80)
    print("üìã –£–ª—É—á—à–µ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:")
    print("   ‚Ä¢ AI –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ø–æ—Å—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ–æ—Ç–æ")
    print("   ‚Ä¢ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã")
    print("   ‚Ä¢ –£–ª—É—á—à–µ–Ω–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ—Å—Ç–∞")
    print("   ‚Ä¢ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º –∏ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–º —Å–ª–æ–≤–∞–º")
    print("   ‚Ä¢ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è")
    print("   ‚Ä¢ –£–º–Ω—ã–µ fallback-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    print("=" * 80)
    
    bot = AIPostGenerator()
    success = bot.generate_and_send_posts()
    
    if success:
        print("\n" + "=" * 50)
        print("‚úÖ –ë–û–¢ –£–°–ü–ï–®–ù–û –í–´–ü–û–õ–ù–ò–õ –†–ê–ë–û–¢–£!")
        print("   –ü–æ—Å—Ç—ã —Å–æ–∑–¥–∞–Ω—ã –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã")
        print("   –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞–π–¥–µ–Ω—ã")
        print("   –ö–æ–Ω—Ç–µ–Ω—Ç –∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏–¥–µ–∞–ª—å–Ω–æ —Å–æ—á–µ—Ç–∞—é—Ç—Å—è")
        print("=" * 50)
        sys.exit(0)
    else:
        print("\n" + "=" * 50)
        print("‚ùå –û–®–ò–ë–ö–ê –ü–†–ò –í–´–ü–û–õ–ù–ï–ù–ò–ò –†–ê–ë–û–¢–´!")
        print("=" * 50)
        sys.exit(1)

if __name__ == "__main__":
    main()
